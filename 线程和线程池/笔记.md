[toc]

参考链接:
<https://llfc.club/articlepage?id=2TayNx5QxbGTaWW5s48vMjtuvCB>

## 01线程的发起

C++ 1 同一线程标准之后，可以自定义一个线程变量，改变量线程启动会掉逻辑

当启动一个线程后，线程可能没有立即执行，如果在局部作用域启动了一个线程，或者main函数中，很可能子线程没运行就被回收了，回收时会调用线程的析构函数，执行terminate操作。所以为了防止主线程退出或者局部作用域结束导致子线程被析构的情况，我们可以通过join，让主线程等待子线程启动运行，子线程运行结束后主线程再运行。

```c++
//01.cpp
#include<iostream>
#include<thread>


void thread_work(std::string str){
    std::cout << "this is in thread "<<std::this_thread::get_id() 
            <<" print str is "<<str <<std::endl;
}
int main(){
    std::string hellow_str = "hellow str";
    std::thread t1(thread_work,hellow_str);
    t1.join();
    return 0;
}
//output
//this is in thread 139785085081344 print str is hellow str
```

### 线程还可以使用仿函数作为参数传递给线程

```c++
//01.cpp
class thread_work_2{
    public:
        void operator()(std::string str){
            std::cout << "this class is in thread "<<std::this_thread::get_id() 
                <<" print str is "<<str <<std::endl;
        }
};
int main(){
    std::string hellow_str = "hellow str";
    std::thread t2(thread_work_2(),hellow_str);
    t2.join();
    return 0;
}

//output
//this class is in thread 139645188667136 print str is hellow str
```

### 线程还可以使用lamda表达式作为参数的

```c++
int main(){
    std::thread t3([](const std::string str){
            std::cout << "this lamda is in thread "<<std::this_thread::get_id() 
                <<" print str is "<<str <<std::endl;
        },hellow_str);
    t3.join();
}
//output
//this lamda is in thread 140605175211776 print str is hellow str
```

### 线程还可以使用bind绑定的function类型作为函数传递

**使用这种方式可以在类外用线程调用类的成员函数**

```c++
//01.cpp
class thread_bind_test{
    public:
        void run(const std::string str){
             std::cout << "this class is in thread use bind "<<std::this_thread::get_id() 
                <<" print str is "<<str <<std::endl;
        }
};
int main(){
    auto fun_t4 = std::bind(&thread_bind_test::run,&base_,std::placeholders::_1);
    std::thread t4(fun_t4,hellow_str);
    t4.join();
}
//output
//this class is in thread use bind 139836595017472 print str is hellow str
```

bind绑定类成员函数时，第一个参数表示对象的成员函数的指针，第二个参数表示对象的地址。
必须显式地指定&Base::diplay_sum，因为编译器不会将对象的成员函数隐式转换成函数指针，所以必须在Base::display_sum前添加&；
使用对象成员函数的指针时，必须要知道该指针属于哪个对象，因此第二个参数为对象的地址 &base

这种方式在转坐标系标定过程中应用，参考Gaussiansplatting相关/gs_transcood/app/main.cpp

```c++
//节选
 std::shared_ptr<Recalib>recalib_ptr = std::make_shared<Recalib>(file_path);
    Recalib* rec= recalib_ptr.get();

    int camera_num = rec->getNums();

    for(int i = 0; i < camera_num; i++)
    {
        auto func = std::bind(&Recalib::load_data,rec,i);
        rec->pool->enqueue(func);
    }
    rec->pool->Wait();
```

在上述代码中我们创建了一个Recalib的指针，让这个指针指向shared_ptr管理的Recalib，通过bind的方式构造func，将func传入线程池pool进行多线程处理

#### 线程的detach

线程允许采用分离的方式在后台独自运行，C++ concurrent programing书中称其为守护线程。
当我们使用detach线程的时候，如果使用局部变量，局部变量可能随着主线程的结束而退出
一般来说我们使用detach线程执行不需要同步的线程

可以通过下面三种方式:
通过智能指针传递参数，因为引用计数会随着赋值增加，可保证局部变量在使用期间不被释放，这也就是我们之前提到的伪闭包策略。
将局部变量的值作为参数传递，这么做需要局部变量有拷贝复制的功能，而且拷贝耗费空间和效率。
将线程运行的方式修改为join，这样能保证局部变量被释放前线程已经运行结束。但是这么做可能会影响运行逻辑。

#### 线程的异常处理

常见的异常处理有两种:
方法1  try catch

```c++
void catch_exception() {
    int some_local_state = 0;
    func myfunc(some_local_state);
    std::thread  functhread{ myfunc };
    try {
        //本线程做一些事情,可能引发崩溃
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }catch (std::exception& e) {
        functhread.join();
        //问题出现抛出异常
        throw;
    }
    functhread.join();
}
```

<font color=red>方法2 手动实现线程对象析构的时候等待线程运行结束</font>

```c++
//01.cpp
class thread_guard{
    private:
        std::thread &_t;
    public:
        explicit thread_guard(std::thread &t) : _t(t){};
        ~thread_guard(){
            if(_t.joinable()){
                _t.join();
            }
        }
    //禁止复制构造函数和拷贝构造函数
    thread_guard(thread_guard const&) = delete;
    thread_guard& operator=(thread_guard const&) = delete;
};

int main(){
    auto fun_t4 = std::bind(&thread_bind_test::run,&base_,std::placeholders::_1);
    std::thread t4(fun_t4,hellow_str);
    thread_guard g_t(t4);
    std::cout << "thread_guard finished "<<std::endl;

    //-----------------------------  也可以使用
    std::shared_ptr<thread_guard>g_ptr = std::make_shared<thread_guard>(std::ref(t4));
    thread_guard * g_t = g_ptr.get();
    std::cout << "thread_guard finished "<<std::endl;
    g_ptr.reset();
}

//output
/*
thread_guard finished 
this class is in thread use bind 139732221298432 print str is hellow str
*/
```

注意到上述程序中，当g_t进入析构时，g_t绑定的线程保证进行join完成，确保在 thread_guard 对象被销毁时，其管理的线程已经完成执行，避免当线程执行时的资源泄露问题。避免了声明线程没有join的问题，可以直接创建线程管理对象，在return之前就会析构线程管理对象。

#### 引用参数

当在线程调用函数需要传递引用参数的时候，需要显示化的指明引用对象将其传递给线程的构造函数
简单来讲，线程函数传入引用的时候，必须用ref指明是引用声明

**简单来说就是在thread在构造的时候会对传入的数据进行一份拷贝(拷贝本身不是深拷贝)。拷贝结束后传入start(线程函数)将按传值的方式进行，从而失去传入引用的特性。使用std::ref是将对象和其地址绑定传入，拷贝后的结果也仍然是其引用。**

```c++
    std::thread t5(thread_work_ref,std::ref(t_5));
    t5.join();
```

在线程thread的源码中
是这样执行的:
```c++
  template <class _Fn, class... _Args, enable_if_t<!is_same_v<_Remove_cvref_t<_Fn>, thread>, int> = 0>
    _NODISCARD_CTOR explicit thread(_Fn&& _Fx, _Args&&... _Ax) {
        _Start(_STD forward<_Fn>(_Fx), _STD forward<_Args>(_Ax)...);
    }
```
声明一个thread的回调函数start 在start中执行传入函数
```c++
template <class _Fn, class... _Args>
    void _Start(_Fn&& _Fx, _Args&&... _Ax) {
        // 1 处
        using _Tuple                 = tuple<decay_t<_Fn>, decay_t<_Args>...>;
        // 2 处
        auto _Decay_copied           = _STD make_unique<_Tuple>(_STD forward<_Fn>(_Fx), _STD forward<_Args>(_Ax)...);
        // 3 处
        constexpr auto _Invoker_proc = _Get_invoke<_Tuple>(make_index_sequence<1 + sizeof...(_Args)>{});
#pragma warning(push)
#pragma warning(disable : 5039) // pointer or reference to potentially throwing function passed to
                                // extern C function under -EHc. Undefined behavior may occur
                                // if this function throws an exception. (/Wall)
        // 4处
        _Thr._Hnd =
            reinterpret_cast<void*>(_CSTD _beginthreadex(nullptr, 0, _Invoker_proc, _Decay_copied.get(), 0, &_Thr._Id));
#pragma warning(pop)
        if (_Thr._Hnd) { // ownership transferred to the thread
            (void) _Decay_copied.release();
        } else { // failed to start thread
            _Thr._Id = 0;
            _Throw_Cpp_error(_RESOURCE_UNAVAILABLE_TRY_AGAIN);
        }
    }
```
23两处
2处是将传入的线程函数和线程函数参数组成一个元组
3处则是实现另一个函数调用器
在_Get_invoke函数中 实际上是执行了invoke操作
```c++
template <class _Tuple, size_t... _Indices>
static unsigned int __stdcall _Invoke(void* _RawVals) noexcept /* terminates */ {
// adapt invoke of user's callable object to _beginthreadex's thread procedure
const unique_ptr<_Tuple> _FnVals(static_cast<_Tuple*>(_RawVals));
_Tuple& _Tup = *_FnVals;
_STD invoke(_STD move(_STD get<_Indices>(_Tup))...);
_Cnd_do_broadcast_at_thread_exit(); // TRANSITION, ABI
return 0;
}
```
对于invoke操作中，则是执行了一个call操作
```c++
CONSTEXPR17 auto invoke(_Callable&& _Obj, _Ty1&& _Arg1, _Types2&&... _Args2) noexcept(
    noexcept(_Invoker1<_Callable, _Ty1>::_Call(
        static_cast<_Callable&&>(_Obj), static_cast<_Ty1&&>(_Arg1), static_cast<_Types2&&>(_Args2)...)))
```
此时会发现传入都是右值引用，在4处将函数调用器和对应的线程函数和参数表绑定。执行调用器中的call函数，此时会发现call中是右值引用参数表，直接传入左值引用，会因为右值引用不能绑定左值而报错

>这里就引出C++11新特性之中的右值引用不能绑定左值的点，因为从右值引用的设计初衷是为了避免不必要的深拷贝，进行对象所有权的转移而不是拷贝，所以右值引用绑定的一般是将亡值，强行将左值引用赋值给右值引用不符合右值引用的设计初衷，所以这一点是不合理的，在编译的过程中就会报错。

**也就是说，thread的回调函数传递是以副本的方式。这里就需要使用std::ref构造一个reference_wrapper对象，再这个对象通过仿函数，当调用对象化的时候就以_T&的形式返回，实现了引用的传递**


这是因为如果默认传递一个右值引用，不能直接绑定左值
而ref是返回一个class reference_wrapper，这个class将累的地址和指针绑定保存，在调用的时候将触发仿函数达到获取外部实参的地址内的数据

#### 使用move操作

有时候传递给线程的参数是独占的，所谓独占就是不支持拷贝赋值和构造，但是我们可以通过std::move的方式将参数的所有权转移给线程，如下

```c++
void deal_unique(std::unique_ptr<int> p) {
    std::cout << "unique ptr data is " << *p << std::endl;
    (*p)++;
    std::cout << "after unique ptr data is " << *p << std::endl;
}
void move_oops() {
    auto p = std::make_unique<int>(100);
    std::thread  t(deal_unique, std::move(p));
    t.join();
    //不能再使用p了，p已经被move废弃
   // std::cout << "after unique ptr data is " << *p << std::endl;
}
//make_unique在c++14中编译
```

## 02 线程的管控

### 线程归属权

在C++中对thread不允许其执行拷贝构造和拷贝赋值, 所以只能通过移动和局部变量返回的方式将线程变量管理的线程转移给其他变量管理。
类似的还有std::mutex, std::ifstream, std::unique_ptr。

在转移线程归属权的时候可以通过move进行转移

```c++
//02.cpp
void do_some_work(){
    while(true){
        std::cout << " this thread id is "<<this_thread::get_id()<<std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
void do_some_other_work(){
    while(true){
        std::cout << " this thread id is other work "<<this_thread::get_id()<<std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
int main(){
    thread t1 = std::thread(do_some_work);    
    thread t2 = std::move(t1);

    //此时t1无效 t1可以再绑定一个函数
    t1 = std::thread(do_some_other_work);   
    std::this_thread::sleep_for(std::chrono::seconds(2000));

    return 0; 
}

/*
output
 this thread id is 140114710877952
 this thread id is other work 140114702485248
 this thread id is 140114710877952
*/
```

在上述线程t2接替t1后，开辟的线程id也一并移交给t2，而move释放后的t1任然可以新承接函数任务

注意:已经分配函数的线程，不能用move，只能用新建的线程move

我们可以手动实现一个join_thread类实现线程的传递
核心思想是 当出现线程接替的时候，如join_thread A = join_thread B，先让A的任务join，等待任务结束后在将B的线程任务move给A
这里给出源码:

```c++
//02.cpp
class joining_thread {
    std::thread  _t;
public:
    joining_thread() noexcept = default;
    template<typename Callable, typename ...  Args>
    explicit  joining_thread(Callable&& func, Args&& ...args):
        _t(std::forward<Callable>(func),  std::forward<Args>(args)...){}
    explicit joining_thread(std::thread  t) noexcept: _t(std::move(t)){}
    joining_thread(joining_thread&& other) noexcept: _t(std::move(other._t)){}
    joining_thread& operator=(joining_thread&& other) noexcept
    {
        //如果当前线程可汇合，则汇合等待线程完成再赋值
        if (joinable()) {
            join();
        }
        _t = std::move(other._t);
        return *this;
    }
    joining_thread& operator()( joining_thread other) noexcept
    {
        //如果当前线程可汇合，则汇合等待线程完成再赋值
        if (joinable()) {
            join();
        }
        _t = std::move(other._t);
        return *this;
    }
    ~joining_thread() noexcept {
        if (joinable()) {
            join();
        }
    }
    void swap(joining_thread& other) noexcept {
        _t.swap(other._t);
    }
    std::thread::id   get_id() const noexcept {
        return _t.get_id();
    }
    bool joinable() const noexcept {
        return _t.joinable();
    }
    void join() {
        _t.join();
    }
    void detach() {
        _t.detach();
    }
    std::thread& as_thread() noexcept {
        return _t;
    }
    const std::thread& as_thread() const noexcept {
        return _t;
    }
};
void thread_work_seq(int max_index){
    for(int i=0;i<max_index;i++){
        std::cout << "this thread id is "<<this_thread::get_id() <<std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
int main(){
    int max_index = 10;
    auto func = std::bind(thread_work_seq,std::placeholders::_1);

    joining_thread tj1(std::thread(func,40));
    joining_thread tj2(func,max_index);
    tj1 = std::move(tj2);
}
/*
//output 节选
this thread id is 140021568886528
this thread id is 140021577279232
this thread id is 140021568886528
this thread id is 140021577279232
this thread id is 140021577279232
this thread id is 140021577279232
this thread id is 140021577279232
*/
```

最后的输出中可以看到 由于线程没有join但是当进行线程交接的时候，会先把tj2的任务join，此时两个线程相互抢占时间片，thread_id也是交替出现的，当tj2.join结束后，后续就只有tj1了，知道tj1安全退出，实现了线程的交替

### 容器存储

在存储线程容器，如vector< thread>结构，在这种结构下线程的加入要用直接插入的emplace_back而不能用带有拷贝的push_back

### 选择运行数量

借用C++标准库的std::thread::hardware_concurrency()函数，它的返回值是一个指标，表示程序在各次运行中可真正并发的线程数量.
我们可以模拟实现一个并行计算的功能，计算容器内所有元素的和

## 03互斥与死锁

#### lock_guard

lock_guard在作用域结束时自动调用其析构函数解锁，这么做的一个好处是简化了一些特殊情况从函数中返回的写法，比如异常或者条件不满足时，函数内部直接return，锁也会自动解开。

```c++
std::mutex mtx;
void thread_word_01(){
    while(true){
        std::lock_guard<std::mutex>lock(mtx);
        shared_data ++;
        std::cout << "this thread id is "<<std::this_thread::get_id()<<" and shared_data is "<<shared_data<<std::endl;
        std::this_thread::yield();
    }
}
int main(){
    std::thread t1 = thread(thread_word_01);
    std::thread t2 = thread(thread_word_01);
    t1.join();
    t2.join();
}

/*
output
this thread id is 140215027353344 and shared_data is 105558
this thread id is 140215035746048 and shared_data is 105559
*/
```

在上述例子中可以看出对shared_data递增的时候，每次只有一个线程在操作shared_data
而使用lock_guard，代替了mtx.lock()和mtx.unlock()，同时由于lock_guard有生命周期，且在函数内部return的时候会自动释放所，避免了死锁问题

#### 如何保证数据安全

举一个例子，如果定义了一个多线程访问的栈，如下所示:

```c++
//03.cpp
template<typename T>
class threadsafe_stack1
{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack1() {}
    threadsafe_stack1(const threadsafe_stack1& other)
    {
        std::lock_guard<std::mutex> lock(other.m);
        //①在构造函数的函数体（constructor body）内进行复制操作
        data = other.data;
    }
    threadsafe_stack1& operator=(const threadsafe_stack1&) = delete;
    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value));
    }
    //问题代码
    T pop()
    {
        std::lock_guard<std::mutex> lock(m);
        auto element = data.top();
        data.pop();
        return element;
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

void test_threadsafe_stack1() {
    threadsafe_stack1<int> safe_stack;
    safe_stack.push(1);
    std::thread t1([&safe_stack]() {
        if (!safe_stack.empty()) {
            std::this_thread::sleep_for(std::chrono::seconds(1));
            safe_stack.pop();
            }
        });
    std::thread t2([&safe_stack]() {
        if (!safe_stack.empty()) {
            std::this_thread::sleep_for(std::chrono::seconds(1));
            safe_stack.pop();
        }
    });
    t1.join();
    t2.join();
}
```

当t1、t2都通过栈非空判断后，如果此时时间片交换，就会出现t1中pop出了值，但是t2中再pop的时候就pop空栈了

解决方式:在pop的时候可以增加一个非空的判断，如果是空的就直接跳过，如

```c++
//03.cpp
struct empty_stack : std::exception
{
    const char* what() const throw() override{
        return "Empty stack exception";
    };
};
     shared_ptr<T> pop(){
        std::lock_guard<std::mutex>lock(m);
        if(data.empty()){return nullptr;}
        shared_ptr<T>res  = make_shared<T>(data.top());
        data.pop();
        return res;
    }
    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if (data.empty()) throw empty_stack();
        value = data.top();
        data.pop();
    }
```

一种是如果当前值存在pop空栈，就抛出错误。或者用shared_ptr承接pop值(避免了拷贝复制，最大限度的提高了运行)
但是存在区别，就是shared_ptr不会应为throw中断程序，throw将直接抛出异常

#### 死锁

死锁一般是由于调运顺序不一致导致的，比如两个线程循环调用。当线程1先加锁A，再加锁B，而线程2先加锁B，再加锁A。那么在某一时刻就可能造成死锁。比如线程1对A已经加锁，线程2对B已经加锁，那么他们都希望彼此占有对方的锁，又不释放自己占有的锁导致了死锁。

实际工作中避免死锁的一个方式就是将加锁和解锁的功能封装为独立的函数，
这样能保证在独立的函数里执行完操作后就解锁，不会导致一个函数里使用多个锁的情况

例如:

```c++
void atomic_lock1() {
    std::cout << "lock1 begin lock" << std::endl;
    t_lock1.lock();
    m_1 = 1024;
    t_lock1.unlock();
    std::cout << "lock1 end lock" << std::endl;
}
void atomic_lock2() {
    std::cout << "lock2 begin lock" << std::endl;
    t_lock2.lock();
    m_2 = 2048;
    t_lock2.unlock();
    std::cout << "lock2 end lock" << std::endl;
}
void safe_lock1() {
    while (true) {
        atomic_lock1();
        atomic_lock2();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
    }
}
void safe_lock2() {
    while (true) {
        atomic_lock2();
        atomic_lock1();
        std::this_thread::sleep_for(std::chrono::milliseconds(5));
    }
}
void test_safe_lock() {
    std::thread t1(safe_lock1);
    std::thread t2(safe_lock2);
    t1.join();
    t2.join();
}
```

但是如果一个函数中同时出现两个互斥量，也会出现相互竞争卡锁的问题:
如:

```c++
//这里并不详细介绍som_big_object和big_object_mgr类，重点说明两类交换
class big_object_mgr {
public:
    big_object_mgr(int data = 0) :_obj(data) {}
    void printinfo() {
        std::cout << "current obj data is " << _obj << std::endl;
    }
    friend void danger_swap(big_object_mgr& objm1, big_object_mgr& objm2);
    friend void safe_swap(big_object_mgr& objm1, big_object_mgr& objm2);
    friend void safe_swap_scope(big_object_mgr& objm1, big_object_mgr& objm2);
private:
    std::mutex _mtx;
    som_big_object _obj;
};
void danger_swap(big_object_mgr& objm1, big_object_mgr& objm2) {
    std::cout << "thread [ " << std::this_thread::get_id() << " ] begin" << std::endl;
    if (&objm1 == &objm2) {
        return;
    }
    std::lock_guard <std::mutex> gurad1(objm1._mtx);
    //此处为了故意制造死锁，我们让线程小睡一会
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::lock_guard<std::mutex> guard2(objm2._mtx);
    swap(objm1._obj, objm2._obj);
    std::cout << "thread [ " << std::this_thread::get_id() << " ] end" << std::endl;
}
```

对于danger_swap，如果出现:

```c++
    std::thread t1(danger_swap, std::ref(objm1), std::ref(objm2));
    std::thread t2(danger_swap, std::ref(objm2), std::ref(objm1));
```

t1和t2会各自拿到一把锁，相互造成死锁
解决方式是 用锁同时锁住两个锁

```c++
void safe_swap(big_object_mgr& objm1, big_object_mgr& objm2) {
    std::cout << "thread [ " << std::this_thread::get_id() << " ] begin" << std::endl;
    if (&objm1 == &objm2) {
        return;
    }
    std::lock(objm1._mtx, objm2._mtx);
    //领养锁管理它自动释放
    std::lock_guard <std::mutex> gurad1(objm1._mtx, std::adopt_lock);
    //此处为了故意制造死锁，我们让线程小睡一会
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::lock_guard <std::mutex> gurad2(objm2._mtx, std::adopt_lock);
    swap(objm1._obj, objm2._obj);
    std::cout << "thread [ " << std::this_thread::get_id() << " ] end" << std::endl;
}
```

std::adopt_lock是告诉gurad1，objm1._mtx锁已经被锁定了，不需要重复上锁
此时如果t1锁住了objm1._mtx, objm2._mtx，t2切换到时间片也不会继续执行，应为两个锁都被锁住了(此时如果一个锁无法正确获取，就会阻塞)。而使用adopt的方式将lock转为lock_guard保证上锁安全

#### 层级锁

如果在一个函数中必须要循环加多个锁，这里就需要手动对每一个锁设置一个权值，保证上锁按照从大到小的权上锁，解锁按照从小到大权解锁

请注意这种利用公共static元素遍历的方式

```c++
//03.cpp
//层级锁
class hierarchical_mutex {
public:
    explicit hierarchical_mutex(unsigned long value) :_hierarchy_value(value),
        _previous_hierarchy_value(0) {}
    hierarchical_mutex(const hierarchical_mutex&) = delete;
    hierarchical_mutex& operator=(const hierarchical_mutex&) = delete;
    void lock() {
        check_for_hierarchy_violation();
        _internal_mutex.lock();
        update_hierarchy_value();
    }
    void unlock() {
        if (_this_thread_hierarchy_value != _hierarchy_value) {
            throw std::logic_error("mutex hierarchy violated");
        }
        _this_thread_hierarchy_value = _previous_hierarchy_value;
        _internal_mutex.unlock();
    }
    bool try_lock() {
        check_for_hierarchy_violation();
        if (!_internal_mutex.try_lock()) {
            return false;
        }
        update_hierarchy_value();
        return true;
    }
private:
    std::mutex  _internal_mutex;
    //当前层级值
    unsigned long const _hierarchy_value;
    //上一次层级值
    unsigned long _previous_hierarchy_value;
    //本线程记录的层级值  表示其实权值 同时限制权值的范围
    static thread_local unsigned long  _this_thread_hierarchy_value;
    void check_for_hierarchy_violation() {
        if (_this_thread_hierarchy_value <= _hierarchy_value) {
            throw  std::logic_error("mutex  hierarchy violated");
        }
    }
    void  update_hierarchy_value() {
        _previous_hierarchy_value = _this_thread_hierarchy_value;
        _this_thread_hierarchy_value = _hierarchy_value;
    }
};
// 保证声明的变量在每个线程中都会有自己独立的实例，而不是所有线程共享一个实例。
thread_local unsigned long hierarchical_mutex::_this_thread_hierarchy_value(ULONG_MAX);

void test_hierarchy_lock() {
    hierarchical_mutex  hmtx1(1000);
    hierarchical_mutex  hmtx2(500);
    std::thread t1([&hmtx1, &hmtx2]() {
        hmtx1.lock();
        hmtx2.lock();
        hmtx2.unlock();
        hmtx1.unlock();
        });
    std::thread t2([&hmtx1, &hmtx2]() {
        hmtx2.lock();
        hmtx1.lock();
        hmtx1.unlock();
        hmtx2.unlock();
        });
    t1.join();
    t2.join();
}
```

## 04 unique_lock

unique_lock和lock_guard基本用法相同，构造时默认加锁，析构时默认解锁，但**unique_lock有个好处就是可以手动解锁**。这一点尤为重要，方便我们控制锁住区域的粒度(加锁的范围大小),也能支持和条件变量配套使用，至于条件变量我们之后再介绍，本文主要介绍锁的相关操作。
例如

```c++
//声明一个unique_lock -- lock
unique_lock<std::mutex>lck(mtx);
//手动解开锁
lck.unlock();
```

unique_lock有解锁的unlock，也会有上锁的lock，lock可以**延迟上锁**，需要搭配defer_lock。**defer_lock**的前提是，你不能自己先lock,否则会报异常。std::defer_lock的意思就是并没有给mutex加锁：初始化了一个没有加锁的mutex。
例如

```c++
//这里只是声明了一个unique_lock对象，但是并没有上锁
unqiue_lock<std::mutex>lck(mtx,std::defer_lock);
...
//延迟上锁
lck.lock();
```

同时 unique_lock可以通过**owns_lock**判断是否持有锁，返回true表示当前进程拥有锁，反之表示没有用有锁
unique_lock也支持adopt_lock领养锁的方式。表示这个互斥量已经被lock了（你必须要把互斥量提前lock了 ，否者会报异常）；
**std::adopt_lock**标记的效果就是假设调用一方已经拥有了互斥量的所有权（已经lock成功了）；通知lock_guard不需要再构造函数中lock这个互斥量了。

<font color=red>注意:一旦mutex被unique_lock管理,不能调用mutex在进行加锁解锁，因为mutex是不能拷贝的，unique_lock其实是获取了mutex的使用权</font>
mutex可以通过unique_lock转移锁的使用权

```c++
//04.cpp
std::mutex mtx;
int shared_data = 10;

std::unique_lock <std::mutex>  get_lock() {
    std::unique_lock<std::mutex>  lock(mtx);
    shared_data++;
    std::cout<<"cur shared_data is "<<shared_data << std::endl;
    return lock;
}
void use_return() {
    std::unique_lock<std::mutex> lock(get_lock());
    shared_data++;
    std::cout<<"cur shared_data is "<<shared_data << std::endl;
}

class thread_guard{
    private:
        thread _t;
    public:
        template<typename _Callable, typename... _Args>
        explicit thread_guard(_Callable&& __f, _Args&&... __args){
            _t = thread(std::forward<_Callable>(__f),std::forward< _Args>( __args)...);
        }
        explicit thread_guard(thread && t1): _t(std::move(t1)){};
        ~thread_guard(){
            if(_t.joinable()){
                _t.join();
            }
        }
};
int main(){
    //以下两种调用方式都可以
    try
    {
        thread_guard gt_1(use_return);
    }
    catch(const std::exception& e)
    {
        std::thread t1 = thread(use_return);
        thread_guard gt_1(std::move(t1));
    }
}

```

通过get_lock实现了mutex在不同unique_lock中的转移
这是因为在C++源码中

```c++
      unique_lock(unique_lock&& __u) noexcept
      : _M_device(__u._M_device), _M_owns(__u._M_owns)
      {
 __u._M_device = 0;
 __u._M_owns = false;
      }
```

函数的返回如果是引用，那么返回就是左值引用，如果是一个对象，返回是作为右值使用的，上述代码get_lock可以直接传递对象实现构造另一个unique_lock，也可以通过下文方式，构造右值引用返回

```c++
std::unique_lock <std::mutex> && get_lock() {
    std::unique_lock<std::mutex>  lock(mtx);
    shared_data++;
    std::cout<<"cur shared_data is "<<shared_data << std::endl;
    return std::move(lock);
}
void use_return() {
    std::unique_lock<std::mutex> lock(get_lock());
    shared_data++;
    std::cout<<"cur shared_data is "<<shared_data << std::endl;
}
```

### 共享锁 shared_lock

试想这样一个场景，对于一个DNS服务，我们可以根据域名查询服务对应的ip地址，它很久才更新一次，比如新增记录，删除记录或者更新记录等。平时大部分时间都是提供给外部查询，对于查询操作，即使多个线程并发查询不加锁也不会有问题，但是当有线程修改DNS服务的ip记录或者增减记录时，其他线程不能查询，需等待修改完再查询。或者等待查询完，线程才能修改。也就是说读操作并不是互斥的，同一时间可以有多个线程同时读，但是写和读是互斥的，写与写是互斥的，简而言之，写操作需要独占锁。而读操作需要共享锁。

需使用共享互斥量std::shared_mutex,std::shared_mutex是C++17标准提出的。
C++14标准可以使用std::shared_time_mutex,

两者共同使用 #include <shared_mutex>

但是两者会存在差别:
shared_mutex：

```
* 提供了 `lock()`, `try_lock()`, 和 `try_lock_for()` 以及 `try_lock_until()` 函数，这些函数都可以用于获取互斥锁。
* 提供了 `try_lock_shared()` 和 `lock_shared()` 函数，这些函数可以用于获取共享锁。
* 当 `std::shared_mutex` 被锁定后，其他尝试获取该锁的线程将会被阻塞，直到该锁被解锁。
```

shared_timed_mutex

```
* 与 `std::shared_mutex` 类似，也提供了 `lock()`, `try_lock()`, 和 `try_lock_for()` 以及 `try_lock_until()` 函数用于获取互斥锁。
* 与 `std::shared_mutex` 不同的是，它还提供了 `try_lock_shared()` 和 `lock_shared()` 函数用于获取共享锁，这些函数在尝试获取共享锁时具有超时机制。
* 当 `std::shared_timed_mutex` 被锁定后，其他尝试获取该锁的线程将会被阻塞，直到该锁被解锁，这与 `std::shared_mutex` 相同。然而，当尝试获取共享锁时，如果不能立即获得锁，`std::shared_timed_mutex` 会设置一个超时，超时过后如果仍然没有获取到锁，则操作将返回失败。
```

如果需要超时机制，就用shared_timed_mutex，否则就用shared_mutex

使用shared_lock(共享锁) 和 lock_guard(互斥锁)分别封装读写功能

```c++
//04.cpp

    class read_write{
    private:
        mutable std::shared_mutex _shared_mutex;
    public:
        read_write(){}
        void read_shared_data(){
            while(true){
                std::shared_lock<std::shared_mutex>_shared_lock(_shared_mutex);
                std::cout << "this thread is "<<this_thread::get_id() << " read shared_data "<<shared_data<<std::endl;
                std::this_thread::sleep_for(std::chrono::seconds(1));
            }
        }
        void write_shared_data(){
            while (true)
            {
                std::unique_lock<std::shared_mutex>_unique_lock(_shared_mutex);
                shared_data++;
                std::cout << "this thread is "<<this_thread::get_id() << " write shared_data "<<shared_data<<std::endl;
                std::this_thread::sleep_for(std::chrono::seconds(1));
             }       
        }
};
int main(){
    auto func_Read = std::bind(&read_write::read_shared_data,&rw_1);
    auto func_Write = std::bind(&read_write::write_shared_data,&rw_1);
    std::thread t1 = std::thread(func_Read);
    std::thread t2 = std::thread(func_Read);
    std::thread t3 = std::thread(func_Write);

    thread_guard gt_1(std::move(t1));
    thread_guard gt_2(std::move(t2));
    thread_guard gt_3(std::move(t3));
}
```

上述代码实现了对shared_data的同时读取，写的时候会阻塞shared_data
注意上述代码一定要在C++17中编译

#### 递归锁 -- recursive_mutex

例如函数a需要获取锁mutex，函数b也需要获取锁mutex，同时函数a中还会调用函数b。如果使用std::mutex必然会造成死锁。但是使用std::recursive_mutex就可以解决这个问题。如下的例子很好说明了这一点：

std::recursive_mutex 与 std::mutex 一样，也是一种可以被上锁的对象，但是和 std::mutex 不同的是，std::recursive_mutex 允许同一个线程对互斥量多次上锁（即递归上锁），来获得对互斥量对象的多层所有权，std::recursive_mutex 释放互斥量时需要调用与该锁层次深度相同次数的 unlock()，可理解为 lock() 次数和 unlock() 次数相同，除此之外，std::recursive_mutex 的特性和 std::mutex 大致相同。

```c++
class recursive_lock_test{
    private:
        std::recursive_mutex r_mtx;
    public:
        void fun1(){
            std::lock_guard<std::recursive_mutex>r_f1(r_mtx);
            std::cout << "in func1 "<<"\n";
        }
        void fun2(){
            std::lock_guard<std::recursive_mutex>r_f1(r_mtx);
            std::cout << "in func2 before func1"<<"\n";
            fun1();
            std::cout << "in func2 after func1"<<"\n";
        }
};
int main(){
    recursive_lock_test rlt1;
    auto func_rec1 = std::bind(&recursive_lock_test::fun1, &rlt1); 
    auto func_rec2 = std::bind(&recursive_lock_test::fun2, &rlt1); 
    thread_guard gt_1(func_rec1);
    thread_guard gt_2(func_rec2);
}   

/*
output
in func2 before func1
in func1 
in func2 after func1
in func1 
*/
```

递归锁的思想，其实在第三节中我们设置权重锁的时候就有体现hierarchical_mutex

## 05 C++线程单例模式演变

### C++ 单例模式

当函数中构建一个局部静态变量，这个局部静态变量只会被初始化一次，以后无论调用几次这个函数，函数内部局部变量不会再被初始化

```c++
//05.cpp
void test_static_fun(){
    static int count = 0;
    std::cout << "static count = "<<count<<std::endl;
    count++;
}
int main(){
    test_static_fun();
    test_static_fun();
    test_static_fun();
    test_static_fun();
}
/*
output:
static count = 0
static count = 1
static count = 2
static count = 3
*/
```

利用这个性质，我们可以创建单例模式的类

```c++
class Single2 {
private:
    Single2()
    {
        std::cout << "this is ctr "<<std::endl;
    }
    Single2(const Single2&) = delete;
    Single2& operator=(const Single2&) = delete;
public:
    static Single2& GetInst()
    {
        static Single2 single;
        return single;
    }
    static shared_ptr<Single2> GetInstant(){
            //make_shared调用的话只能访问public变量，所以这里使用new
            static shared_ptr<Single2> s_ptr = std::shared_ptr<Single2>(new Single2()); 
            return s_ptr;
    }
};

int main(){
    Single2& sgl = Single2::GetInst();
    shared_ptr<Single2>ptr = Single2::GetInstant();  
}
```

### 饿汉模式初始化于懒汉模式初始化

单例模式分为两种，一种是饿汉式，一种是懒汉式。
最简单的区分:在构建单例模式的时候，饿汉模式是当类被加载的时候，静态变量就会被初始化。懒汉模式就是必须要调用类的getInstance函数才会获取类的单例对象

#### 饿汉模式

```c++
//05.cpp
//饿汉式
class Single2Hungry
{
private:
    Single2Hungry()
    {
    }
    Single2Hungry(const Single2Hungry&) = delete;
    Single2Hungry& operator=(const Single2Hungry&) = delete;
public:
    static Single2Hungry* GetInst()
    {
        if (single == nullptr)
        {
            single = new Single2Hungry();
        }
        return single;
    }
private:
    static Single2Hungry* single;
};
Single2Hungry* Single2Hungry::single = Single2Hungry::GetInst();
void thread_func_s2(int i)
{
    std::cout << "this is thread " << i << std::endl;
    std::cout << "inst is " << Single2Hungry::GetInst() << std::endl;
}
void test_single2hungry()
{
    std::cout << "s1 addr is " << Single2Hungry::GetInst() << std::endl;
    std::cout << "s2 addr is " << Single2Hungry::GetInst() << std::endl;
    for (int i = 0; i < 3; i++)
    {
        std::thread tid(thread_func_s2, i);
        tid.join();
    }
}
```

恶汉模式中已经注册了single，在多线程调用前就已经创建了实例对象，饿汉式是从使用角度规避多线程的安全问题

#### 懒汉模式初始化

```c++
//05.cpp
class SinglePointer
{
private:
    SinglePointer()
    {
    }
    SinglePointer(const SinglePointer&) = delete;
    SinglePointer& operator=(const SinglePointer&) = delete;
public:
    static SinglePointer* GetInst()
    {
        if (single != nullptr)
        {
            return single;
        }
        s_mutex.lock();
        if (single != nullptr)
        {
            s_mutex.unlock();
            return single;
        }
        single = new SinglePointer();
        s_mutex.unlock();
        return single;
    }
private:
    static SinglePointer* single;
    static std::mutex s_mutex;
};
SinglePointer* SinglePointer::single = nullptr;
std::mutex SinglePointer::s_mutex;
void thread_func_lazy(int i)
{
    std::cout << "this is lazy thread " << i << std::endl;
    std::cout << "inst is " << SinglePointer::GetInst() << std::endl;
}
void test_singlelazy()
{
    for (int i = 0; i < 3; i++)
    {
        std::thread tid(thread_func_lazy, i);
        tid.join();
    }
    //何时释放new的对象？造成内存泄漏
}
```

懒汉模式使用这个方式GetInst()才会创建对象，但是要注意的是在多线程调用中，需要用锁的方式，在每个线程调用是判断是否已经被初始化
这种方式存在一个很严重的问题，就是当多个线程都调用单例函数时，我们不确定资源是被哪个线程初始化的。
回收指针存在问题，存在多重释放或者不知道哪个指针释放的问题。

#### 使用智能指针的形式优化

如果说使用对资源的自动释放，首先考虑的就是智能指针

```c++
class SingleAuto
{
private:
    SingleAuto()
    {
    }
    SingleAuto(const SingleAuto&) = delete;
    SingleAuto& operator=(const SingleAuto&) = delete;
public:
    ~SingleAuto()
    {
        std::cout << "single auto delete success " << std::endl;
    }
    static std::shared_ptr<SingleAuto> GetInst()
    {
        if (single != nullptr)
        {
            return single;
        }
        s_mutex.lock();
        if (single != nullptr)
        {
            s_mutex.unlock();
            return single;
        }
        single = std::shared_ptr<SingleAuto>(new SingleAuto);
        s_mutex.unlock();
        return single;
    }
private:
    static std::shared_ptr<SingleAuto> single;
    static std::mutex s_mutex;
};
std::shared_ptr<SingleAuto> SingleAuto::single = nullptr;
std::mutex SingleAuto::s_mutex;
void test_singleauto()
{
    auto sp1 = SingleAuto::GetInst();
    auto sp2 = SingleAuto::GetInst();
    std::cout << "sp1  is  " << sp1 << std::endl;
    std::cout << "sp2  is  " << sp2 << std::endl;
    //此时存在隐患，可以手动删除裸指针，造成崩溃
    // delete sp1.get();
}
```

当class在析构的时候就会自动释放智能指针

#### call_once

C++11 提出了call_once函数，我们可以配合一个局部的静态变量once_flag实现线程安全的初始化。
多线程调用call_once函数时，会判断once_flag是否被初始化，如没被初始化则进入初始化流程，调用我们提供的初始化函数。
但是同一时刻只有一个线程能进入这个初始化函数。

下面我们给出使用只能指针管理单例模式的例子

```c++
//05.cpp
template<typename C>
class Singleton
{
public:
    Singleton(const Singleton &) = delete;
    Singleton(Singleton &&) = delete;
    Singleton &operator=(const Singleton &) = delete;
    Singleton &operator=(Singleton &&) = delete;

    protected:
    Singleton()
    {
    }
    virtual ~Singleton()
    {
    }
    public:

    template<class... Args>
    static std::shared_ptr<C> Instance(Args&&... args)
    {
        //保证在多线程中单例安全
        static std::once_flag oc;
        std::call_once(oc, [&]{
            (std::cout << "input id is "<<... <<args) <<std::endl;
            instance = std::make_shared<C>(std::forward<Args>(args)...);
        });
        return instance;
    }
    private:
    static std::shared_ptr<C> instance;
    };

template<typename C> 
    std::shared_ptr<C> Singleton<C>::instance = nullptr;

class MyClass
{
public:
    MyClass()
        :m_value(10)
    {}
 
    MyClass(int value)
        :m_value(value)
    {}
 
    ~MyClass()
    {
        std::cout << "xigou" << std::endl;
    }

    void destory()
    {
        std::cout << "destory" << std::endl;
    }

    void print()
    {
        std::cout << m_value << std::endl;
    }
private:
    int m_value;
};

void thread_func_auto(int i)
{
    std::cout << "this is auto thread " << i << std::endl;
    Singleton<MyClass>::Instance(i)->print();
    std::cout << "inst is MyClass " << Singleton<MyClass>::Instance(i)->get_pointer() << std::endl;
}
void test_sing_leauto()
{
    for (int i = 0; i < 3; i++)
    {
        std::thread tid(thread_func_auto, i);
        tid.join();
    }
}

int main(){
    auto sg1 = Singleton<MyClass>::Instance();
    sg1->print();
    test_sing_leauto();
    return 0;
}

/*
output
this is auto thread 0
input id is 0
0
inst is MyClass 0x7f00cc000b50
this is auto thread 1
0
inst is MyClass 0x7f00cc000b50
this is auto thread 2
0
*/
```

可以看出，每次调用print 输出的my_value都是0，就说明即是我们传入了不同i初始化，此时都只是调用的是同一个对象

使用智能指针管理MyClass值声明了一次 （因为Singleton<MyClass>类型只会初始化一次）

并且input id is 0 只在id是0的时候输出，就说明了
通常情况下，std::once_flag 被声明为一个全局静态变量，并在调用 std::call_once 函数时作为参数传递进去。当 std::call_once 函数被多个线程同时调用时，**std::once_flag 会保证其中的函数只会被其中一个线程执行，其他线程会被阻塞直到该函数执行完成**。

###  双重加锁检测
在C++ 中 new是先声明地址 在构造 再返回地址
但是由于编译优化的过程构造和返回地址顺序可能相反。
在多线程的时候就会出现先创建地址 返回地址 还没有构造但是另一个线程就调用了没有构造地址的内存
这是有问题的

一种解决思路是使用双重枷锁
```c++
 static Singleton * GetInstance() {
        /*
         * 双重检测解决多线程问题：
         * 第一次访问这个接口的时候才会涉及到资源竞争，需要加锁（写操作）
         * 第二次访问这个接口的时候，不涉及资源竞争，不需要加锁（读操作）
         */
        if (_instance == nullptr) {
            // RAII：在类的生命周期进行资源管理
            std::lock_guard<std::mutex> lock(_mutex);
            if (_instance == nullptr) {
                _instance = new Singleton();
                /*
                 * new 是一个操作符
                 * （1）分配内存
                 * （2）调用构造函数
                 * （3）返回指针
                 * 多线程环境下，CPU 会进行指令重排（reorder）
                 * 有可能先调用（1）、（3），再调用（2），导致要操作对象数据的时候，对象数据还没有初始化，产生异常
                */
               //程序正常终止时返回函数
                atexit(Destructor);
            }
        }
        return _instance;
    }
private:
    static void Destructor() {
    if (nullptr != _instance) {
        delete _instance;
        _instance = nullptr;
    }
}
```
上述问题还是需要手动析构调用的函数的(要释放掉new出来的内容)

锁必须在第一个if下，不然相当于每一个线程进来都要上锁判断，这是不合理的

当然最简单的一种还是延迟构造：
```c++
static Singleton& GetInstance(){
    static Singleton s;
    return s;
}
```


## 06.条件变量

对于一个场景:  -- **单生产单消费模型**
A线程判断num是不是1，如果是则num++ 如果不是就放弃时间片
B线程判断num是不是2，如果是则num-- 如果不是就放弃时间片

这个场景可以使用互斥锁来实现，但是使用互斥锁的话，当线程A检测到num不是1进入睡眠，B线程可能已经完成输出，此时A还在睡眠，这就造成时间资源的浪费
改进的方式就是使用条件变量来实现，一旦完成立刻通知被阻塞的线程


这里简单介绍一下condition_variable和其绑定锁的关系
在调用是一般是这样的
```c++
locker.lock()
cv.wait(locker,pred)
```
而在wait的过程中 伪代码如下:
```
while(!pred())							  
	等待signal，并调用locker.unlock()		
	接受signal返回并调用locker.lock()		
```

我们给出源码:
```c++

    void
    wait(unique_lock<mutex>& __lock, _Predicate __p)
    {
        while (!__p())
            wait(__lock);
    }

    template<typename _Lock>
      void
      wait(_Lock& __lock)
      {
	shared_ptr<mutex> __mutex = _M_mutex;
	unique_lock<mutex> __my_lock(*__mutex);
	_Unlock<_Lock> __unlock(__lock);
	// *__mutex must be unlocked before re-locking __lock so move
	// ownership of *__mutex lock to an object with shorter lifetime.
	unique_lock<mutex> __my_lock2(std::move(__my_lock));
	_M_cond.wait(__my_lock2);
      }

    //notify的实现 认为_M_cond是一个更底层的class
        void
    notify_one() noexcept
    {
      lock_guard<mutex> __lock(*_M_mutex);
      _M_cond.notify_one();
    }

    void
    notify_all() noexcept
    {
      lock_guard<mutex> __lock(*_M_mutex);
      _M_cond.notify_all();
    }
```


```c++
//06.cpp
void condition_test_AB(){
    std::mutex mtx;
    std::condition_variable data_A;
    std::condition_variable data_B;
    int num = 1;
    std::thread t1([&](){
        for(;;){
            std::unique_lock<std::mutex>lck(mtx);
            data_A.wait(lck,[&](){
                return num == 1;
            });
            num++;
            printf("thread A add num\n");
            data_B.notify_one();
        }
    });
    std::thread t2([&](){
        for(;;){
            std::unique_lock<std::mutex>lck(mtx);
            data_B.wait(lck,[&](){
                return num == 2;
            });
            num--;
            printf("thread B mins num\n");
            data_A.notify_one();
        }
    });

    t1.join();
    t2.join();
}
```

此时发现
thread A add num
thread B mins num
是交替输出的，而不是等待一秒才弹出来输出的。-- **这也是最早的单生产单消费者模型**

#### 线程安全队列

我们曾在第三讲实现过线程安全队列/栈 threadsafe_stack1，在那个时候对于多线程都执行pop的时候，我们需要在pop函数中额外判断当前是否为空，在继续执行

此时可以做一个修改，在线程安全栈/队列中加入一个条件变量，在pop前条件遍历控制队列必须为空

```c++
template<typename T>
class thread_safe_queue{
    private:
        std::mutex mtx;
        int max_size = 1000;
        std::condition_variable is_full;
        std::condition_variable is_empty;
        std::queue<T>data_queue;

        thread_safe_queue(){};
        thread_safe_queue(thread_safe_queue&) = delete;
        thread_safe_queue& operator=(const thread_safe_queue&) = delete;
    public:
        static thread_safe_queue& getInst(){
            static thread_safe_queue ts_q;
            return ts_q;
        };

        void push(const T& val){
            std::unique_lock<std::mutex>lck(mtx);
            is_full.wait(lck,[this](){
                return data_queue.size() < max_size;
            });
            data_queue.push(val);
            is_empty.notify_one();
        };
        void pop(shared_ptr<T>&ptr){
            std::unique_lock<std::mutex>lck(mtx);
            is_empty.wait(lck,[this](){
                return !data_queue.empty();
            });
            ptr = std::make_shared<T>(data_queue.front());
            data_queue.pop();
            is_full.notify_one();
        }
};

void test_thread_safe_queue(){
    thread_safe_queue<int>& ts_q = thread_safe_queue<int>::getInst();
    std::thread produer([&ts_q](){
        for(int i=0;;++i){
            ts_q.push(i);
            printf("producer push data %d\n",i);
        }
    });
    std::thread comsuer1([&ts_q](){
        for(;;){
            shared_ptr<int>s_ptr = nullptr;
            ts_q.pop(s_ptr);
            printf("comsuer1 pop data %d\n",*s_ptr);
        }
    });
    std::thread comsuer2([&ts_q](){
        for(;;){
            shared_ptr<int>s_ptr = nullptr;
            ts_q.pop(s_ptr);
            printf("comsuer2 pop data %d\n",*s_ptr);
        }
    });

    produer.join();
    comsuer1.join();
    comsuer2.join();
}
```

## 07.future、promise、async和线程池

### async用法

async是用于一步执行函数的模板函数，返回一个std::future对象，这个对象用于获取函数的返回值

下面给出一个案例:

```c++
//07.cpp
#include<future>
// 定义一个异步任务
std::string fetchDataFromDB(std::string query) {
    // 模拟一个异步任务，比如从数据库中获取数据
    std::this_thread::sleep_for(std::chrono::seconds(5));
    return "Data: " + query;
}
int main() {
    // 使用 std::async 异步调用 fetchDataFromDB
    std::future<std::string> resultFromDB = std::async(std::launch::async, fetchDataFromDB, "Data");
    // 在主线程中做其他事情
    std::cout << "Doing something else..." << std::endl;
    // 从 future 对象中获取数据
    std::string dbData = resultFromDB.get();
    std::cout << dbData << std::endl;
    return 0;
}
```

此处的
get实际上是一个阻塞操作，当我们使用async把线程任务分发出去之后，我们可以让主线程执行其他工作，当我们需要获取返回的值的时候，使用get操作就会阻塞主线程等待分发出去的线程返回并且获取器返回值

下面介绍async的启动模式:

```c++
std::future<std::string> resultFromDB = std::async(std::launch::async, fetchDataFromDB, "Data");
```

**async可以接受不同的启动策略，在std::launch中定义**
std::launch::deferred：这种策略意味着任务将在调用std::future::get()或std::future::wait()函数时延迟执行。换句话说，任务将在需要结果时同步执行--在调用get的时候才会执行线程的工作。
std::launch::async：执行这个语句之后，函数将在另一个线程中立即执行

std::launch::async | std::launch::deferred：这种策略是上面两个策略的组合。任务可以在一个单独的线程上异步执行，也可以延迟执行，具体取决于实现
具体使用哪一种情况，将由cpu和操作系统确定，这也是async的默认策略

### future的wait和get和wait_for

std::future::get() 是一个阻塞调用，用于获取 std::future 对象表示的值或异常。如果异步任务还没有完成，get() 会阻塞当前线程，直到任务完成。如果任务已经完成，get() 会立即返回任务的结果。重要的是，get() 只能调用一次，因为它会移动或消耗掉 std::future 对象的状态。一旦 get() 被调用，std::future 对象就不能再被用来获取结果。(一个future就只能get一次)

std::future::wait() 也是一个阻塞调用，但它与 get() 的主要区别在于 wait() 不会返回任务的结果。它只是等待异步任务完成。如果任务已经完成，wait() 会立即返回。如果任务还没有完成，wait() 会阻塞当前线程，直到任务完成。与 get() 不同，wait() 可以被多次调用，它不会消耗掉 std::future 对象的状态。

同时也可以使用wait_for或wait_unti方法来检查异步操作是否已经完成

```c++
//07.cpp
if(resultFromDB.wait_for(std::chrono::seconds(10)) == std::future_status::ready){
    printf("process finsihed\n");
}
else{
    printf("process not finished\n");
}
```

在上述代码中，我们等待10s进行一次检查，如果此时future_status状态是ready，说明已经完毕。注意 如果例子在10s前就完成进入ready状态，这里会立即输出

这个方式在项目中用来检查异步线程的执行状态

### packaged_tast和std::future关联

std::packaged_task是一个可调用目标，它包装了一个任务，该任务可以在另一个线程上运行。它可以捕获任务的返回值或异常，并将其存储在std::future对象中，以便以后使用。

std::future代表一个异步操作的结果。它可以用于从异步任务中获取返回值或异常。

```
1.创建一个std::packaged_task对象，该对象包装了要执行的任务。
2.调用std::packaged_task对象的get_future()方法，该方法返回一个与任务关联的std::future对象。
3.在另一个线程上调用std::packaged_task对象的operator()，以执行任务。
在需要任务结果的地方，调用与任务关联的std::future对象的get()方法，以获取任务的返回值或异常。
```


使用案例:

```c++
int my_task(){
    std::this_thread::sleep_for(std::chrono::seconds(5));
    std::cout << "my task run 5s "<<std::endl;
    return 42;
}
void use_package(){
    //int()表示返回了一个无参的int类型
    std::packaged_task<int()>task(my_task);
    std::future<int>result = task.get_future();
    //这里最好传一个右值
    std::thread t(std::move(task));
    t.detach();

    int value = result.get();
    std::cout << "result is "<<value<<std::endl;
}
/*output
my task run 5s 
result is 42
*/
```

在上述案例中，首先创建了task对象，
将future对象用get_future和task绑定，此时task就是一个仿函数，可以将其传递给另一个异步的线程

如果绑定task存在参数 就按下面方式定义

```c++
//int(int)表示my_task含有一个参数 然后在创建线程的时候传入参数
std::packaged_task<int(int)>task(my_task);
std::thread t(std::move(task),10);
```

### promise

使用packaged_task和future 或者 async和future可以让主线程获取异步调用的线程的返回值
C++还引入了promise，于在某一线程中设置某个值或异常，而std::future则用于在另一线程中获取这个值或异常。

```c++
void set_value(std::promise<int>prom){
    prom.set_value(10);
}
void use_promise(){
    std::promise<int>prom;
    std::future<int>fut = prom.get_future();
    std::thread t(set_value,std::move(prom));
    std::cout << "value set by the thread :" << fut.get()<<std::endl;
    t.join();
}
```

在上面代码中，首先创建了一个 std::promise< int>，并通过get_future方法将其和future对象fut绑定，之后通过调用set_value函数方法执行线程，并在主线程中通过调用fut.get()方法获取这个值。注意，在调用fut.get()方法时，如果promise的值还没有被设置，则该方法会阻塞当前线程，直到值被设置为止。

整个过程和packaged_task很相似，但是线程调用却是将promise对象看做一个参数，而不是一个task任务。promise变量实现了参数在异步线程之间的传递

除了promise的sset_value方法，还有set_exception()，让promise接受一个std::exception_ptr参数，该参数可以通过调用std::current_exception()方法获取。下面是一个例子：

```c++
#include <iostream>
#include <thread>
#include <future>
void set_exception(std::promise<void> prom) {
    try {
        // 抛出一个异常
       	std::this_thread::sleep_for(std::chrono::seconds(2));
        int result = 42; // 模拟的计算结果
        
        // 设置值
        promise.set_value(result);
    } catch(...) {
        // 设置 promise 的异常
        prom.set_exception(std::current_exception());
    }
}
int main() {
    // 创建一个 promise 对象
    std::promise<void> prom;
    // 获取与 promise 相关联的 future 对象
    std::future<void> fut = prom.get_future();
    // 在新线程中设置 promise 的异常
    std::thread t(set_exception, std::move(prom));
    // 在主线程中获取 future 的异常
    try {
        std::cout << "Waiting for the thread to set the exception...\n";
        fut.get();
    } catch(const std::exception& e) {
        std::cout << "Exception set by the thread: " << e.what() << '\n';
    }
    t.join();
    return 0;
}
/*
Waiting for the thread to set the exception...
Exception set by the thread: An error occurred!
*/
```

std::current_exception() 是 C++ 标准库 <exception> 中提供的函数之一，它用于获取当前线程中最近抛出的异常的指针。
一般情况下，当一个异常被抛出时，异常处理机制会将异常传播到调用栈的更高层，直到被适当的异常处理机制捕获。但有时候，你可能希望在异常被捕获之后仍然能够访问异常对象。这就是 std::current_exception() 函数的作用所在。

这里使用std::current_exception()获取throw抛出的异常类型，并将其传递给promise变量

此外还需要注意一点，如果promise被释放了而与之绑定的future对象还没有，调用这个future对象的get会报错

使用promise获取async中的异步线程变量
```c++
template<typename T>
T test_async_promise_work(T input_value){
    //get res 
    input_value.set_value(30);
    return input_value;
}   
void test_async_promise(){
    auto func = std::bind(test_async_promise_work<std::promise<int>>,std::placeholders::_1);
    std::promise<int> cal_thread;
    std::future<std::promise<int>> fut_p = std::async(std::launch::async,func,std::move(cal_thread));
    auto ans = std::move(fut_p.get());
    std::future<int> cal_thread_fu = ans.get_future();
    std::cout << "Thread cal is "<<cal_thread_fu.get()<<std::endl;
}
```


### shared_future

我们知道一个future对象一旦被get，将不能再次使用底层被move了。
使用std::shared_future，实现多个线程获取一个异步操作结果的场景，也就是多次get
注意，如果是将shared_future对象在多个线程中传递，就不能用move传递右值。这种用法是错误的，一个future通过隐式构造传递给shared_future之后，这个shared_future被移动传递给两个线程是不合理的，因为第一次移动后shared_future的生命周期被转移了，接下来myThread3构造时用的std::move(future)future已经失效了，会报错，一般都是no state 之类的错误。

```c++
void set_shared_value(promise<int>prom){
    std::this_thread::sleep_for(std::chrono::seconds(1));
    int cur_prom = 110;
    prom.set_value(cur_prom);
}
template<typename T>
void get_shared(std::shared_future<T>fut,std::promise<T>res){
    try
    {
        res.set_value(fut.get());
    }
    catch(const std::future_error &e)
    {
        std::cerr << e.what() << '\n';
    }
}
void test_promise_with2thread(){
    std::promise<int>prom;
    std::shared_future<int>fut = prom.get_future();
    std::thread t1(set_shared_value,std::move(prom));
    t1.join();

    std::promise<int>res_1,res_2;
    std::future<int>f_1 = res_1.get_future();
    std::future<int>f_2 = res_2.get_future();
    std::thread t2(get_shared<int>,fut,std::move(res_1));
    std::thread t3(get_shared<int>,fut,std::move(res_2));

    std::cout << f_1.get() << std::endl;
    std::cout << f_2.get() << std::endl;
    t2.join();
    t3.join();
}
```

为什么shared_future和future的get有这种区别呢？
我们给出源码

```c++
      //shared_future
      /// Retrieving the value
      const _Res&
      get() const { return this->_M_get_result()._M_value(); }

      //future
        _Res
      get()
      {
        typename _Base_type::_Reset __reset(*this);
        return std::move(this->_M_get_result()._M_value());
      }
```

当然，future提供了share方法，将当前future对象转换为shared_future

```c++
//future
shared_future<_Res> share() noexcept;
template<typename _Res>
inline shared_future<_Res>
future<_Res>::share() noexcept
{ return shared_future<_Res>(std::move(*this)); }
```

### *** 线程池

我们利用上面提到的std::packaged_task和std::promise构建线程池，提高并发能力
线程池是一种多线程处理形式，它处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件）,则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。

**也就是说，线程池实际上实现了一个生产消费模型**

线程池可以避免在处理短时间任务时创建与销毁线程的代价，它维护着多个线程，等待着监督管理者分配可并发执行的任务，从而提高了整体性能。

我们给出两套线程池的代码

#### 最终版

注意：在作者给出的代码中，存在当任务数量超过线程数量的时候，由于没有wait操作，会出现当主线程中线程池进入析构的时候，每一个线程只会哪一个任务出来执行 -- 这样就导致任务队列中等待的任务无法全部执行。

所以我们提出修改:
增加条件变量 cv_wait_
增加等待函数 wait
进入析构前，进入等待状态 while循环一直判断任务队列是否为空，为空才会退出

```c++
#ifndef __AUTHOR_THREAD_POOL_H__
#define __AUTHOR_THREAD_POOL_H__
#include <atomic>
#include <condition_variable>
#include <future>
#include <iostream>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>
#include<functional>

class ThreadPool  {
public:
    ThreadPool(const ThreadPool&) = delete;
    ThreadPool&        operator=(const ThreadPool&) = delete;
    static ThreadPool& instance() {
        static ThreadPool ins;
        return ins;
    }
    static ThreadPool& instance(int thread_num) {
        static ThreadPool ins(thread_num);
        return ins;
    }
    using Task = std::packaged_task<void()>;
    ~ThreadPool() {
        if(!stop_.load()){
            wait();
            stop();
            printf("ThreadPool Destroyed\n");
        }
    }
    void wait_for_empty(){
        this->wait();
    }
    //这里属于C++新特性 使用auto作为函数返回值的时候，需要用->声明返回auto的对象
    //std::decltype(args) 返回args的类型
    template <class F, class... Args>
    auto commit(F&& f, Args&&... args) -> std::future<decltype(f(args...))> {
        using RetType = decltype(f(args...));
        if (stop_.load())
            return std::future<RetType>{};
        auto task = std::make_shared<std::packaged_task<RetType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<RetType> ret = task->get_future();
        {
            std::lock_guard<std::mutex> cv_mt(cv_mt_);
            //这里传入task的lamda表达式
            tasks_.emplace([task] { (*task)(); });
        }
        cv_lock_.notify_one();
        return ret;
    }
    int idleThreadCount() {
        return thread_num_;
    }
private:
    ThreadPool(unsigned int num = 5)
        : stop_(false) {
            {
                if (num < 1)
                    thread_num_ = 1;
                else
                    thread_num_ = num;
            }
            start();
    }
    void start() {
        for (int i = 0; i < thread_num_; ++i) {
            pool_.emplace_back([this]() {
                while (!this->stop_.load()) {
                    Task task;
                    {
                        std::unique_lock<std::mutex> cv_mt(cv_mt_);
                        //当线程池停止或者线程中有任务才会向下执行
                        this->cv_lock_.wait(cv_mt, [this] {
                            return this->stop_.load() || !this->tasks_.empty();
                        });
                        //如果此时队列中没有任务，就说明可以关闭了
                        if (this->tasks_.empty() && this->stop_.load())
                            return;
                        //此时是两种情况 1.stop 清空任务队列 2.没停 正常取任务出来
                        task = std::move(this->tasks_.front());
                        this->tasks_.pop();
                    }
                    //atomic_int的父类atomic_base重载了++ -- 所以这里可以并不用fetch
                    this->thread_num_--;
                    //调用仿函数的方式
                    task();
                    this->thread_num_++;
                    cv_wait_.notify_all();
                }
            });
        }
    }


    void wait(){
        std::unique_lock<std::mutex>lck(cv_mt_);
        while(!tasks_.empty()){
            cv_wait_.wait(lck);
        }
    }


    void stop() {
        stop_.store(true);
        cv_lock_.notify_all();
        for (auto& td : pool_) {
            if (td.joinable()) {
                std::cout << "join thread " << td.get_id() << std::endl;
                td.join();
            }
        }
        cv_wait_.notify_all();
    }
private:
    std::mutex               cv_mt_;
    std::condition_variable  cv_lock_;
    std::condition_variable  cv_wait_;
    std::atomic_bool         stop_;
    std::atomic_int          thread_num_;
    std::queue<Task>         tasks_;
    std::vector<std::thread> pool_;
};
#endif  // !__THREAD_POOL_H__
```

#### 我们自己的参见thread_pool.h thread_pool.cpp


### 08.函数式编程
C++函数式编程是一种编程范式，它将计算视为数学上的函数求值，并避免改变状态和使用可变数据。在函数式编程中，程序是由一系列函数组成的，每个函数都接受输入并产生输出，而且没有任何副作用。

在C++中，函数式编程可以使用函数指针、函数对象（functor）和lambda表达式等机制来实现。这些机制允许您编写可以像普通函数一样调用的代码块，并将它们作为参数传递给其他函数或作为返回值返回。

C++11引入了一些新功能，如constexpr函数和表达式模板，这些功能使得在C++中进行函数式编程更加容易和直观。

我们给出list类型的快速排序
```c++
template<typename T>
std::list<T> sequential_quick_sort(std::list<T> input)
{
    if (input.empty())
    {
        return input;
    }
    std::list<T> result;
    //  ① 将input中的第一个元素放入result中，并且将这第一个元素从input中删除
    result.splice(result.begin(), input, input.begin());  
    //  ② 取result的第一个元素，将来用这个元素做切割，切割input中的列表。
    T const& pivot = *result.begin();    
    //  ③std::partition 是一个标准库函数，用于将容器或数组中的元素按照指定的条件进行分区，
    // 使得满足条件的元素排在不满足条件的元素之前。
    // 所以经过计算divide_point指向的是input中第一个大于等于pivot的元素
    auto divide_point = std::partition(input.begin(), input.end(),
            [&](T const& t) {return t < pivot; });    
    // ④ 我们将小于pivot的元素放入lower_part中
    std::list<T> lower_part;
    lower_part.splice(lower_part.end(), input, input.begin(),
        divide_point);  
    // ⑤我们将lower_part传递给sequential_quick_sort 返回一个新的有序的从小到大的序列
    //lower_part 中都是小于divide_point的值
        auto new_lower(
            sequential_quick_sort(std::move(lower_part)));    
    // ⑥我们剩余的input列表传递给sequential_quick_sort递归调用，input中都是大于divide_point的值。
        auto new_higher(
            sequential_quick_sort(std::move(input)));    
        //⑦到此时new_higher和new_lower都是从小到大排序好的列表
        //将new_higher 拼接到result的尾部
        result.splice(result.end(), new_higher);    
        //将new_lower 拼接到result的头部
        result.splice(result.begin(), new_lower);   
        return result;
}
```

## 08 Actor和CSP设计模式
传统的并发设计经常都是通过共享内存加锁保证逻辑安全，这种模式有几个缺点，包括1 频繁加锁影响性能，2 耦合度高。后来大家提出了Actor和CSP设计模式。
### Actor模式
简单点说，actor通过消息传递的方式与外界通信。消息传递是异步的。每个actor都有一个邮箱，该邮箱接收并缓存其他actor发过来的消息，actor一次只能同步处理一个消息，处理消息过程中，除了可以接收消息，不能做任何其他操作。
每一个类独立在一个线程里称作Actor，Actor之间通过队列通信，比如Actor1 发消息给Actor2， Actor2 发消息给Actor1都是投递到对方的队列中。好像给对方发邮件，对方从邮箱中取出一样。如下图
<img src="https://cdn.llfc.club/1696556496577.jpg">

### CSP模式 
CSP和Actor类似，只不过CSP将消息投递给channel，至于谁从channel中取数据，发送的一方是不关注的。简单的说Actor在发送消息前是直到接收方是谁，而接受方收到消息后也知道发送方是谁，更像是邮件的通信模式。

CSP模式最典型的应用就是生产消费模型，生产者向管线(仓库)中不断加入，由消费者从中取出，生产者从不会关心自己生产的任务被谁取走
例如:
```c++
//08.cpp
#include <iostream>
#include <queue>
#include <mutex>
#include <thread>
#include <condition_variable>

template <typename T>
class Channel {
private:
    std::queue<T> queue_;
    std::mutex mtx_;
    std::condition_variable cv_producer_;
    std::condition_variable cv_consumer_;
    size_t capacity_;
    bool closed_ = false;
public:
    Channel(size_t capacity = 0) : capacity_(capacity) {}
    ~Channel(){
        close();
    }
    bool send(T value) {
        std::unique_lock<std::mutex> lock(mtx_);
        cv_producer_.wait(lock, [this]() {
            // 对于无缓冲的channel，我们应该等待直到有消费者准备好
            return (capacity_ == 0 && queue_.empty()) || queue_.size() < capacity_ || closed_;
        });
        if (closed_) {
            return false;
        }
        queue_.push(value);
        cv_consumer_.notify_one();
        return true;
    }
    bool receive(T& value) {
        std::unique_lock<std::mutex> lock(mtx_);
        cv_consumer_.wait(lock, [this]() { return !queue_.empty() || closed_; });
        if (closed_ && queue_.empty()) {
            return false;
        }
        value = queue_.front();
        queue_.pop();
        cv_producer_.notify_one();
        return true;
    }
    void close() {
        std::unique_lock<std::mutex> lock(mtx_);
        closed_ = true;
        cv_producer_.notify_all();
        cv_consumer_.notify_all();
    }
};
// 示例使用
int main() {
    Channel<int> ch(10);  // 10缓冲的channel
    std::thread producer([&]() {
        for (int i = 0; i < 15; ++i) {
            ch.send(i);
            printf("send %d\n",i);
        }
        });
    std::thread producer2([&]() {
        for (int i = 15; i < 30; ++i) {
            ch.send(i);
            printf("send %d\n",i);
        }
        });
    std::thread consumer([&]() {
        //std::this_thread::sleep_for(std::chrono::milliseconds(500)); // 故意延迟消费者开始消费
        int val;
        while (ch.receive(val)) {
            printf("receive %d\n",val);
        }
    });
   
    producer.join();
    producer2.join();
    consumer.join();
    return 0;
}
```

### ***浅谈一下异步操作
想象有这么一个功能
funcA中异步出一个计算函数，但在funA中并不需要等待这个异步结果的返回
funcB需要等待这个函数计算完毕，根据这个返回结果执行操作

我们给出一种解决思路:
```c++
int asyncFunc() {
    std::this_thread::sleep_for(std::chrono::seconds(3));
    std::cout << "this is asyncFunc" << std::endl;
    return 0;
}
void func1(std::future<int>& future_ref) {
    std::cout << "this is func1" << std::endl;
    future_ref = std::async(std::launch::async, asyncFunc);
}
void func2(std::future<int>& future_ref) {
    std::cout << "this is func2" << std::endl;
    auto future_res = future_ref.get();
    if (future_res == 0) {
        std::cout << "get asyncFunc result success !" << std::endl;
    }
    else {
        std::cout << "get asyncFunc result failed !" << std::endl;
        return;
    }
}
void first_method() {
    std::future<int> future_tmp;
    func1(future_tmp);
    func2(future_tmp);
}
```
如何实现一个不会阻碍主线程的异步操作呢
要注意 将异步操作发送出去后，在C++中需要考虑线程的声明周期和回收，如果detch出去的线程没有在主线程关闭之前执行完，程序还是会引发问题。

所以在把异步任务函数放置到ParallenExe中去后，还需要将返回值进行一个wait操作
```c++
template<typename Func,typename ...Args>
auto ParallenExe(Func&&func,Args &&...args)->std::future<decltype(func(args...))>{
    typedef decltype(func(args...)) ReType;
    std::function<ReType()>  bind_func = std::bind(std::forward<Func>(func), std::forward<Args>(args)...);
    std::packaged_task<ReType()>task(bind_func);
    auto rt_future = task.get_future();
    std::thread t(std::move(task));
    t.detach();

    return rt_future;
}
void test_pall(){
    std::cout << "start test pall"<<std::endl;
    int i = 0;
    auto rt_future = ParallenExe([](int i){
        while (i<3)
        {
            i++;
            std::cout << "ParllenExe thread func " << i << " times" << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
    },i);
    std::cout <<"end test pall"<<std::endl;
    rt_future.wait();
}
```
## *** 09.原子操作和内存模型

### 原子操作
标准的原子操作定义位于< atomic>内，我们可以通过atomic<>定义一些原子类型的变量，如atomic<bool>,atomic<int> 这些类型的操作全是原子化的。
从C++17开始，所有的原子类型都包含一个静态常量表达式成员变量，std::atomic::is_always_lock_free。这个成员变量的值表示在任意给定的目标硬件上，原子类型X是否始终以无锁结构形式实现。如果在所有支持该程序运行的硬件上，原子类型X都以无锁结构形式实现，那么这个成员变量的值就为true；否则为false。

### 内存次序
对于原子类型上的每一种操作，我们都可以提供额外的参数，从枚举类std::memory_order取值，用于设定所需的内存次序语义（memory-ordering semantics）。

存储（store）操作，可选用的内存次序有std::memory_order_relaxed、std::memory_order_release或std::memory_order_seq_cst。

载入（load）操作，可选用的内存次序有std::memory_order_relaxed、std::memory_order_consume、std::memory_order_acquire或std::memory_order_seq_cst。

“读-改-写”（read-modify-write）操作，可选用的内存次序有std::memory_order_relaxed、std::memory_order_consume、std::memory_order_acquire、std::memory_order_release、std::memory_order_acq_rel或std::memory_order_seq_cst。

简单介绍一下这些存储逻辑
```
std::memory_order_relaxed：
在存储操作中：不对内存访问顺序做任何保证，允许乱序执行。
在载入操作中：不对内存访问顺序做任何保证，允许乱序执行。
在读-改-写操作中：不对内存访问顺序做任何保证，允许乱序执行。适用于无依赖关系的原子操作。

std::memory_order_acquire：
在存储操作中：保证前面的所有读取和存储操作都在该存储操作之前执行。
在载入操作中：保证该载入操作之前的所有读取和存储操作都在该载入操作之前执行。
在读-改-写操作中：保证前面的所有读取和存储操作都在该读-改-写操作之前执行，并且该读-改-写操作必须在后续的存储和读取操作之前执行。

std::memory_order_release：
在存储操作中：保证该存储操作之后的所有读取和存储操作都在该存储操作之前执行。
在载入操作中：保证该载入操作之后的所有读取和存储操作都在该载入操作之前执行。
在读-改-写操作中：保证该读-改-写操作之后的所有读取和存储操作都在该读-改-写操作之前执行，并且该读-改-写操作必须在前面的存储和读取操作之后执行。

std::memory_order_consume：
在载入操作中：保证对于与该载入操作依赖关系的后续读取操作，这些读取操作都在该载入操作之前执行。适用于处理依赖关系的原子操作。

std::memory_order_acq_rel：
在读-改-写操作中：结合了std::memory_order_acquire和std::memory_order_release，既保证前面的读取和存储操作都在该读-改-写操作之前执行，又保证后续的读取和存储操作都在该读-改-写操作之前执行。

std::memory_order_seq_cst：
在存储、载入和读-改-写操作中：提供最严格的内存同步语义，保证所有的原子操作都按顺序执行，且对所有线程可见。
```

具体场景:
```c++
//memory_order_relaxed 允许乱序执行，提高并发性能。
//std::memory_order_acquire 和 std::memory_order_release
//适用于具有读取和写入依赖关系的场景，确保正确的数据同步。

std::atomic<int> my_data(0);
std::atomic<bool> ready(false);
void writer_thread(){
    my_data.store(42,std::memory_order_relaxed);
    ready.store(true,std::memory_order_acquire);
}
void reader_thread(){
    while(!ready.load(std::memory_order_release)){
        std::cout << "Waiting for ready load..."<<std::endl;
    }
    int value = my_data.load(std::memory_order_relaxed);
    std::cout << "Value read by reader thread: " << value << std::endl;
}
void test_acq_rel(){
    std::thread writer(writer_thread);
    std::thread reader(reader_thread);

    writer.join();
    reader.join();
}
```
#### ****宽松内存序 std::memory_order_relaxed 宽松字节序
如图是一个4核CPU的示意图
<img src="https://cdn.llfc.club/1697539893049.jpg">
StoreBuffer就是一级Cache， Catche是二级Cache，Memory是三级Cache。
每个标识CPU的块就是core，上图画的就是4核结构。每两个core构成一个bank，共享一个cache。四个core共享memory。

每个CPU所作的store均会写到store buffer中，每个CPU会在任何时刻将store buffer中结果写入到cache或者memory中。

**CPU使用MESI(写时效协议)协议保证数据一致性，在MESI协议中，每次写入只有一个CPU负责写入数据，其他核心知识同步这个写入，当写入CPU将数据写如cache后，他会广播一个“失效”请求告诉其他所有CPU核心**

MESI协议对应四种不同的标记
M:已经修改
E:独占
S:共享
I:已经失效

已修改告诉其他CPU修改已经完成，其他CPU可以向cache中写入数据
独占表示数据只是加载到CPU的store buffer中，其他的 CPU 核，并没有加载对应的数据到自己的 store buffer 里。这时我们可以自由的写入数据，不需要告诉其他CPU核心

共享状态就是在多核中同时加载了同一份数据。所以在共享状态下想要修改数据要先向所有的其他 CPU 核心广播一个请求，要求先把其他 CPU 核心里面的 cache ，都变成无效的状态，然后再更新当前 cache 里面的数据。
如果变量a此刻在各个cpu的StoreBuffer中，那么CPU1核修改这个a的值，放入cache时通知其他CPU核写失效，因为同一时刻仅有一个CPU核可以写数据，但是其他CPU核是可以读数据的，那么其他核读到的数据可能是CPU1核修改之前的。这就涉及我们提到的改动序列了。
```
**两个序列改动术语**
1 “synchronizes-with“ : 同步, “A synchronizes-with B” 的意思就是 A和B同步，
简单来说如果多线程环境下，有一个线程先修改了变量m，我们将这个操作叫做A，
之后有另一个线程读取变量m，我们将这个操作叫做B，
那么B一定读取A修改m之后的最新值。也可以称作 A “happens-before“ B，即A操作的结果对B操作可见，A的操作在B执行之前就发生。

2 “happens-before“ : 先行，
”A happens-before B” 的意思是如果A操作先于B操作，那么A操作的结果对B操作可见。”
！！！并不一定限制A的操作一定发生在B之前，而是如果A先跑，A的操作一定对B可见！！！
```
<font color=red>！！！ happens-before 并不一定限制A的操作一定发生在B之前，而是如果A先跑，A的操作一定对B可见！！！</font>


#### 关于std::memory_order_relaxed
1 作用于原子变量
2 不具有synchronizes-with关系 即不同线程获取的数值不一定是修改后的值
3 对于同一个原子变量，在同一个线程中具有happens-before关系, 在同一线程中不同的原子变量不具有happens-before关系，可以乱序执行。

例如在一个func中，
```c++
void fun(){
    atomic_int a,b;
    a.store(100,std::memory_order_relaxed);   //(1)
    b.stroe(100,std::memory_order_relaxed);  //(2)
}
```
(2)可能执行在(1)之前

4 多线程情况下不具有happens-before关系。

具体例子如下:
```c++
std::atomic<bool> x, y;
std::atomic<int> z;
void write_x_then_y(){
    x.store(true,std::memory_order_relaxed);
    y.store(true,std::memory_order_relaxed);
}
void read_y_then_x(){
    while(!y.load(std::memory_order_relaxed)){
        std::cout<<" load y false "<<std::endl;
    }
    if(x.load(std::memory_order_relaxed)){
        ++z;
    }
}
void test_order_relaxed(){
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load()!=0);
}
```
上述代码中，运行在 assert(z.load()!=0);会触发错误

**1 从cpu架构分析**
假设线程t1运行在CPU1上，t2运行在CPU3上，那么t1对x和y的操作，t2是看不到的。
比如当线程t1运行至1处将x设置为true，t1运行至2处将y设置为true。这些操作仅在CPU1的store buffer中，还未放入cache和memory中，CPU2自然不知道。
如果CPU1先将y放入memory，那么CPU2就会读取y的值为true。那么t2就会运行至3处从while循环退出，进而运行至4处，此时CPU1还未将x的值写入memory， 
t2读取的x值为false，进而线程t2运行结束，然后CPU1将x写入true, t1结束运行，最后主线程运行至5处，因为z为0,所以触发断言。

**2 从宽松内存序分析**
因为memory_order_relaxed是宽松的内存序列，它只保证操作的原子性，并不能保证多个变量之间的顺序性，也不能保证同一个变量在不同线程之间的可见顺序

总之，memory_order_relaxed保证了多线程对同一个变量的原子操作的安全性，只是可见性会有延迟罢了。


#### 先行

##### 顺序线性

单线程情况下前面的语句先执行，后面的语句后执行。操作a先于操作b，那么操作b可以看到操作a的结果。我们称操作a顺序先行于操作b。
也称作 a 将依赖关系带给 b, 也理解为b依赖于a。

#### 线程线性
例如 线程A i++ 线程B 访问 s[i] 如果A  happens-before B 如果线程A先执行，那么B线程获取的i一定是++之后的最新的结果
也可以理解为A  synchronizes-with B


实际上 在计算机的底层中，对于没有依赖关系的操作也不一定是按照顺序执行的
例如:
```c++
void func(){
    int a,b,c;
    ++a ;   //（1）
    ++b;    //（2）
    c = a+b;
}
```
(1)和(2)本身没有依赖关系，所以在底层汇编操作的时候，(1)和(2)未必是按照(1) ->(2)的 只是在进入c=a+b之前，需要调用(1)和(2)完成后的结果

#### memory_order_seq_cst
memory_order_seq_cst代表全局一致性顺序，可以用于 store, load 和 read-modify-write 操作, 实现 sequencial consistent 的顺序模型. 在这个模型下, 所有线程看到的所有操作都有一个一致的顺序, 即使这些操作可能针对不同的变量, 运行在不同的线程.

例如在之前的例子中，使用memory_order_seq_cst
```c++

void write_x_then_y() {
    x.store(true, std::memory_order_seq_cst);  // 1
    y.store(true, std::memory_order_seq_cst);  // 2
}
void read_y_then_x() {
    while (!y.load(std::memory_order_seq_cst)) { // 3
        std::cout << "y load false" << std::endl;
    }
    if (x.load(std::memory_order_seq_cst)) { //4
        ++z;
    }
}
void TestOrderSeqCst() {
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load() != 0); // 5
}
```
这样就不会导致断言
保证了读取顺序的一致性

#### Acquire-Release

在 acquire-release 模型中, 会使用 memory_order_acquire, memory_order_release 和 memory_order_acq_rel 这三种内存顺序. 它们的用法具体是这样的:

对原子变量的 load 可以使用 memory_order_acquire 内存顺序. 这称为 acquire 操作.

对原子变量的 store 可以使用 memory_order_release 内存顺序. 这称为 release 操作.

read-modify-write 操作即读 (load) 又写 (store), 它可以使用 memory_order_acquire, memory_order_release 和 memory_order_acq_rel:
```
如果使用 memory_order_acquire, 则作为 acquire 操作;
如果使用 memory_order_release, 则作为 release 操作;
如果使用 memory_order_acq_rel, 则同时为两者.
```
修改如下
```c++
void write_x_then_y() {
    x.store(true, std::memory_order_release);  // 1
    y.store(true, std::memory_order_release);  // 2
}
void read_y_then_x() {
    while (!y.load(std::memory_order_acquire)) { // 3
        std::cout << "y load false" << std::endl;
    }
    if (x.load(std::memory_order_acquire)) { //4
        ++z;
    }
}
void TestOrderSeqCst() {
    std::thread t1(write_x_then_y);
    std::thread t2(read_y_then_x);
    t1.join();
    t2.join();
    assert(z.load() != 0); // 5
}
```
Acquire-release 的开销比 sequencial consistent 小. 在 x86 架构下, memory_order_acquire 和 memory_order_release 的操作不会产生任何其他的指令, 只会影响编译器的优化: 任何指令都不能重排到 acquire 操作的前面, 且不能重排到 release 操作的后面; 否则会违反 acquire-release 的语义. 因此很多需要实现 synchronizes-with 关系的场景都会使用 acquire-release.

#### memory_order_consume
memory_order_consume 可以用于 load 操作. 使用 memory_order_consume 的 load 称为 consume 操作. 如果一个 consume 操作在同一个原子变量上读到了一个 release 操作写入的值, 或以其为首的 release sequence 写入的值, 则这个 release 操作 “dependency-ordered before” 这个 consume 操作.

```c++
void ConsumeDependency() {
    std::atomic<std::string*> ptr;
    int data;
    std::thread t1([&]() {
        std::string* p = new std::string("Hello World"); // (1)
        data = 42; // (2)
        ptr.store(p, std::memory_order_release); // (3)
        });
    std::thread t2([&]() {
        std::string* p2;
        while (!(p2 = ptr.load(std::memory_order_consume))); // (4)
        assert(*p2 == "Hello World"); // (5)
        assert(data == 42); // (6)
        });
    t1.join();
    t2.join();
}
```
4处使用memory_order_consume读取p2 他和3处构成依赖关系
由于3依赖于1   5依赖于4 
所以5处获取的p2一定是来自于3处修改后的


### 自旋锁的实现
自旋锁是一种在多线程环境下保护共享资源的同步机制，逻辑是当一个线程尝试获取锁的时候，如果锁已经被其他线程持有，那么这个线程会不断的循环检查锁的状态直到成功获取锁

自旋锁可以基于std::atomic_flag成立。类型std::atomic_flag的对象在初始化时清零，随后即可通过成员函数test_and_set()查值并设置成立，或者由clear()清零。整个过程只有这两个操作。

std::atomic_flag的test_and_set成员函数是一个原子操作，他会先检查std::atomic_flag当前的状态是否被设置过，
1 如果没被设置过(比如初始状态或者清除后)，将std::atomic_flag当前的状态设置为true，并返回false。
2 如果被设置过则直接返回ture。


一开始 std::atomic_flag被设置为false  当有线程获取锁的时候，test_and_set返回false 并将flag设置为true，之后其他线程进来访问锁的时候，因为flag是true test_and_set返回为true 进入等待

```c++
void test_and_set(bool& flag){
    if(!flag ){
        flag  = true;
        //false表示正常获取锁
        return false;  
    }
    else{
        //true表示未能正常获取锁
        return true;
    }
}
```

```c++
class SpinLock{
public:
    void lock(){
        //自旋等待，直到成功获取到锁
        while(flag.test_and_set(std::memory_order_acquire));   

    }
    void unlock(){
        flag.clear(std::memory_order_release);
    }
private:
    std::atomic_flag flag= ATOMIC_FLAG_INIT; //0
};
void test_spinlock(){
    SpinLock slock;
    std::thread t1([&slock](){
        slock.lock();
        for (int i = 0; i < 3; i++) {
            std::cout << "*";
            }
        std::cout << std::endl;
        slock.unlock();
    });
    std::thread t2([&slock](){
        slock.lock();
        for (int i = 0; i < 3; i++) {
            std::cout << "?";
            }
        std::cout << std::endl;
        slock.unlock();
    });

    t1.join();
    t2.join();
}   
```
自旋锁保证了多线程调用的时候，仅有一个线程在同一个时刻进入test_and_set
但是 自旋锁带了CPU空转，导致性能上的损耗，自旋锁适用于锁竞争不激烈、临界区小的场景，可以避免上下文切换的开销


### 单例模式改良:
在单例模式中，我们不用call_once 和 once_flag，使用智能指针构建单例模式
```c++
class SingleAuto
{
private:
    SingleAuto()
    {
    }
    SingleAuto(const SingleAuto&) = delete;
    SingleAuto& operator=(const SingleAuto&) = delete;
public:
    ~SingleAuto()
    {
        std::cout << "single auto delete success " << std::endl;
    }
    static std::shared_ptr<SingleAuto> GetInst()
    {
        if (single != nullptr)
        {
            return single;
        }
        s_mutex.lock();
        if (single != nullptr)
        {
            s_mutex.unlock();
            return single;
        }
        //这里不能使用make_shared,make_shared会出现无法查找ctor函数
        single = std::shared_ptr<SingleAuto>(new SingleAuto);
        s_mutex.unlock();
        return single;
    }
private:
    static std::shared_ptr<SingleAuto> single;
    static std::mutex s_mutex;
};
std::shared_ptr<SingleAuto> SingleAuto::single = nullptr;
std::mutex SingleAuto::s_mutex;

```
这里存在一个问题:对于new的汇编，是由指令顺序的，有以下两种情况:
allocate一块内存空间 -> 调用construct对象 -> 返回构造对象地址
allocate一块内存空间 -> 返回开辟空间地址  -> 调用construct对象

假设有两个线程都调用GetInstant  (没有上锁）
如果是第二种情况，线程A new的时候 刚开辟一块空间，另一个线程中检测到single不是空的就直接返回，但是此时没有调用construct对象，返回的地址将无法使用

这里我们使用内存模型修改
```c++
class SingleAutoRefine
{
private:
    SingleAutoRefine()
    {
    }
    SingleAutoRefine(const SingleAutoRefine&) = delete;
    SingleAutoRefine& operator=(const SingleAutoRefine&) = delete;
public:
    ~SingleAutoRefine()
    {
        std::cout << "single auto delete success " << std::endl;
    }
    static std::shared_ptr<SingleAutoRefine> GetInst()
    {
        if (_is_init.load(std::memory_order_acquire))
        {
            return single;
        }
        s_mutex.lock();
        if (_is_init.load(std::memory_order_acquire))
        {
            s_mutex.unlock();
            return single;
        }
        //这里不能使用make_shared,make_shared会出现无法查找ctor函数
        single = std::shared_ptr<SingleAutoRefine>(new SingleAutoRefine);
        _is_init.store(true,std::memory_order_release);
        s_mutex.unlock();
        return single;
    }
private:
    static std::shared_ptr<SingleAutoRefine> single;
    static std::mutex s_mutex;
    static std::atomic<bool> _is_init;
};
std::shared_ptr<SingleAutoRefine> SingleAutoRefine::single = nullptr;
std::mutex SingleAutoRefine::s_mutex;
std::atomic<bool> SingleAutoRefine::_is_init(false);
```

## 10.无锁并发队列
### ***环形队列
我们要实现无锁并发，经常会用到一种结构无锁队列，而无锁队列和我们经常使用的队列颇有不同，它采用的是环状的队列结构，为什么成环呢？主要有两个好处，一个是成环的队列大小是固定的，另外一个我们通过移动头和尾就能实现数据的插入和取出。

<img src="https://cdn.llfc.club/4a6ee05475ca071cc608c9eb35920af.png">
<img src="https://cdn.llfc.club/1698926107471.jpg">


#### 用锁实现环形队列
```c++
//10.cpp
template<typename T,size_t Cap>
class circle_que_mutex{
public:
    //std::allocator<T>::allocator(_max_size) 分配空间大小
    circle_que_mutex():_max_size(Cap+1),_data(std::allocator<T>().allocate(_max_size)),_head(0),_tail(0){}
    circle_que_mutex(const circle_que_mutex&)=delete;
    circle_que_mutex& operator=(const circle_que_mutex&) volatile = delete;
    circle_que_mutex& operator=(const circle_que_mutex&) = delete;
    ~circle_que_mutex(){
        std::lock_guard<std::mutex>lock(_mtx);
        while(_head!=_tail){
            //调用destroy方法
            std::allocator<T>().destroy(_data + _head);
            _head = (_head+1)%_max_size;
        }
        //调用回收操作 -- 释放由 allocate() 方法分配的内存空间
        std::allocator<T>().deallocate(_data, _max_size);
    }


    template<typename ...Args>
    bool emplace(Args && ...args){
        std::lock_guard<std::mutex>lock(_mtx);
        //判断队列是否满了
        if((_tail + 1 )% _max_size == _head){
            std::cout << "circle que full ! "<<std::endl;
            return false;
        }
        //在尾部构造一个T类型对象 构造参数为args...
        std::allocator<T>().construct(_data+_tail,std::forward<Args>(args)...);
        _tail = (_tail + 1 )& _max_size;
        return true;
    }

    //push 实现两个版本 一个实现左值 一个实现右值
    bool push(const T&val){
        std::cout << "called push const T& version "<<std::endl;
        return emplace(std::move(val));
    }
    bool push(const T&&val){
        std::cout << "called push const T&& version "<<std::endl;
        return emplace(std::move(val));
    }
    //pop 实现出队列
    bool pop(T& val){
        std::lock_guard<std::mutex>lock(_mtx);
        //判断头部和尾部指针是否重合，重合则表示队列为空
        if(_head == _tail){
            std::cout << "circular que empty! "<<std::endl;
            return false;
        }
        //取出头部
        val = std::move(_data[_head]);
        //更新head指针
        _head = (_head+1)%_max_size;
        return true;
    }

private:
    size_t _max_size;
    T* _data;
    std::mutex _mtx;
    size_t _head = 0;
    size_t _tail = 0;
};
```

#### 无锁队列
如果使用原子变量代替锁来实现环形队列，就是无锁并发队列
这里使用到原子变量的两个修改操作:
```c++
bool std::atomic<T>::compare_exchange_weak(T &expected, T desired);
bool std::atomic<T>::compare_exchange_strong(T &expected, T desired);
```

将当前原子变量和expected比较，如果当前值和expected相同，将原子变量变为desired的参数值，并返回true。如果不相等，就将**expected更新为原子变量的值**，返回false

强比较可以这么理解:
```c++
template <typename T>
bool atomic<T>::compare_exchange_strong(T &expected, T desired) {
    std::lock_guard<std::mutex> guard(m_lock);
    if (m_val == expected)
        m_val = desired;
        return true;
    else
        expected = m_val;
        return false;
}
```
一般来说 弱比较的开销更小


无锁的环形队列如下:
```c++
template<typename T,size_t Cap>
class circle_que_atomic{
public:
    circle_que_atomic():_max_size(Cap+1),
                    _data(std::allocator<T>().allocate(_max_size)),
                    _atomic_using(false),
                    _head(0),
                    _tail(0){}
    circle_que_atomic(const circle_que_atomic&) = delete;
    circle_que_atomic& operator=(const circle_que_atomic&) volatile = delete;
    circle_que_atomic& operator=(const circle_que_atomic&)= delete;
    ~circle_que_atomic(){
        //循环销毁
        bool use_expected = false;
        bool use_desire = true;
        //这里是实现了一个自旋锁  
        /*
            _atomic_using为false 和 use_expected一致 
            compare_exchange_strong 返回true 并将_atomic_using改为use_desire(true)
            而在_atomic_using为true的时候，返回为false，这里会一直阻塞
        */
        do{
            use_expected = false;
            use_desire = true;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
        
        //调用元素内部的析构函数
        while(_head != _tail){
            std::allocator<T>().destroy(_data + _head);
            _head = (_head + 1)% _max_size;
        }
        //调用收回
        std::allocator<T>().deallocate(_data,_max_size);

        //释放自旋锁
        do{
            use_expected = true;
            use_desire = false;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
    }

    template<typename ...Args>
    bool emplace(Args ...args){
        bool use_expected = false;
        bool use_desire = true;
        do{
            use_expected = false;
            use_desire = true;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));

        //判断队列是否满了
        if((_tail + 1)% _max_size == _head){
            std::cout << "circle que is full !"<<std::endl;
            do{
                use_expected = true;
                use_desire = false;
            }
            while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
            return false;
        }
        std::allocator<T>().construct(_data + _tail,std::forward<Args>(args)...);
        _tail = (_tail+1)%_max_size;

        do{
            use_expected = true;
            use_desire = false;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
        return true;
    }

    bool push(const T&val){
        return emplace(val);
    }
    bool push(const T&&val){
        return emplace(std::move(val));
    }

    bool pop(T& val){
        bool use_expected = false;
        bool use_desire = true;
        do{
            use_expected = false;
            use_desire = true;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));

        //判断是否队列空
        if(_head == _tail){
            std::cout << "circle que is empty "<<std::endl;
            do{
                use_expected = true;
                use_desire = false;
            }
            while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
            return false;
        }

        val = std::move(_data[_head]);
        _head = (_head + 1)% _max_size;
        do{
            use_expected = true;
            use_desire = false;
        }
        while(!_atomic_using.compare_exchange_strong(use_expected,use_desire));
        return true;
    }

private:
    size_t _max_size;
    T* _data;
    std::atomic<bool>_atomic_using;
    size_t _head = 0;
    size_t _tail = 0;
};
```

上述代码存在问题:如果是多线程访问，此时由于自旋锁的存在，实际上只有一个线程会执行pop/push，其他线程都在自旋
可以考虑将head、tail修改为原子变量进行修改
```c++
//最终版
template<typename T,size_t Cap>
class circle_que_thread_atomic{
public:
    circle_que_thread_atomic():_max_size(Cap+1),
                                                            _data(std::allocator<T>().allocate(_max_size)),
                                                            _head(0),_tail(0),_tail_update(0){}
    circle_que_thread_atomic(const circle_que_thread_atomic&)=delete;
    circle_que_thread_atomic &operator=(const circle_que_thread_atomic&) volatile = delete;
    circle_que_thread_atomic &operator=(const circle_que_thread_atomic&)  = delete;

    ~circle_que_thread_atomic(){
        while(_head!=_tail){
            std::allocator<T>().destroy(_data+_head);
            _head = (_head +1)%_max_size;
        }
        std::allocator<T>().deallocate(_data,_max_size);
    }

    bool push(const T&val){
        size_t t;
        //使用while循环 避免当多线程竞争的时候，导致_tail的不同步
        do{
            t = _tail.load(std::memory_order_acquire);
            if((t+1)%_max_size == _head.load(std::memory_order_acquire)){
                std::cout <<"circle que is full "<<std::endl;
                return false;
            }
        }while(!_tail.compare_exchange_strong (t,(t+1)%_max_size,
                                            std::memory_order_release,std::memory_order_release));
        //如果上述while循环能跳出 此时tail就已经指向下一位空缺位置了
        _data[t] = val;
        size_t tailup;
        do{
            tailup = t;
        }while(_tail_update.compare_exchange_strong(tailup,(tailup+1)%_max_size,
                                             std::memory_order_release,std::memory_order_release));
        return true;
    }

    bool pop(T& val){
        size_t h;
        do{
            h = _head.load(std::memory_order_relaxed);
            if(h == _tail.load(std::memory_order_acquire)){
                std::cout << "circular que empty ! " << std::endl;
                return false;
            }

             //判断如果此时要读取的数据和tail_update是否一致，如果一致说明尾部数据未更新完
            if (h == _tail_update.load(std::memory_order_acquire)) 
            {
                return false;
            }
            val = _data[h]; // 2处
        }while(!_head.compare_exchange_strong(h,(h+1)%_max_size,
                             std::memory_order_release,std::memory_order_release));
        return true;
    }

private:
    size_t _max_size;
    T* _data;
    std::atomic<size_t>_head;
    std::atomic<size_t>_tail;
    /*
    增加另一个原子变量_tail_update来标记尾部数据是否修改完成，
    如果尾部数据没有修改完成，此时其他线程pop时获取的数据就是不安全的，
    所以pop要返回false。
    */
    std::atomic<size_t>_tail_update;
};
```

## 11.利用栅栏实现同步
除了memory_order_seq_cst顺序，其他的顺序都不能保证原子变量修改的值在其他多线程中看到的顺序是一致的

注意 有时候对于两个线程，load我们使用acquire，store我们使用release操作，但是这并不一定保证是线性的，因为不能保证store线程一定在load之前。acquire-relaese只是说如果A先于B A的操作对B可见，并没有保证A一定在B之前。

而memory_order_seq_cst代表全局一致性顺序，可以用于 store, load 和 read-modify-write 操作, 实现 sequencial consistent 的顺序模型。这个模型下, 所有线程看到的所有操作都有一个一致的顺序, 即使这些操作可能针对不同的变量, 运行在不同的线程.

例如:
```c++
void write_x()
{
    x.store(true, std::memory_order_release); //a
}
void write_y()
{
    y.store(true, std::memory_order_release); //b
}
void read_x_then_y()
{
    while (!x.load(std::memory_order_acquire));
    if (y.load(std::memory_order_acquire))   //c
        ++z;
}
void read_y_then_x()
{
    while (!y.load(std::memory_order_acquire));
    if (x.load(std::memory_order_acquire))   //d
        ++z;
}
```
a执行x.store(true)先被线程c读取，而此时线程b对y的store还没有被c读取到新的值，所以此时c读取的x为true，y为false。同样的道理，d可以读取b修改y的最新值，但是没来的及读取x的最新值，那么读取到y为true，x为false。
**如果一个线程对变量执行release内存序的store操作，另一个线程不一定会马上读取到**

#### 栅栏

我们可以简单介绍一下
```c++
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed); 
    y.store(true,std::memory_order_relaxed);  
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));  
    if(x.load(std::memory_order_relaxed))  
        ++z;
}
```
使用relaxed，我们不能确定xy的存储顺序
可以做如下修改
```c++
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed); 
    y.store(true,std::memory_order_acquire);  
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_release));  
    if(x.load(std::memory_order_relaxed))  
        ++z;
}
```

如果线程执行到if(x.load(std::memory_order_relaxed))  处 那么说明y一定是true的，而memory_order_acquire执行了，说明其前面的内容也一定执行了

栅栏机制类似memory_order_release
```c++
//11.cpp
void write_x_then_y_fence()
{
    x.store(true, std::memory_order_relaxed);  //1
    std::atomic_thread_fence(std::memory_order_release);  //2
    y.store(true, std::memory_order_relaxed);  //3
}
void read_y_then_x_fence()
{
    while (!y.load(std::memory_order_relaxed));  //4
    std::atomic_thread_fence(std::memory_order_acquire); //5
    if (x.load(std::memory_order_relaxed))  //6
        ++z;
}
```
和前文思路一直，如果可以通过while判断 说明y一定是true 说明一定执行了3，而由于atomic_thread_fence存在，5处保证6不会先于5写入内存，同样2能保证3不会先于2执行，进而实现1和6的同步

## 12.基于锁实现线程安全队列和栈容器

### 实现一个线程安全栈
```c++
struct empty_stack : std::exception
{
    const char* what() const throw();
};

template<typename T>
class SafeThreadStack{
private:
    std::stack<T>data;
    mutable std::mutex mtx;
    std::condition_variable condition_empty;
public:
    SafeThreadStack(){}
    SafeThreadStack(const SafeThreadStack& other){
        std::lock_guard<std::mutex>lock(other.mtx);
        data = other.data;
    }
    SafeThreadStack& operator=(const SafeThreadStack&)=delete;
    void push(T &new_val){
        std::lock_guard<std::mutex>lock(mtx);
        data.push(std::move(new_val));
        condition_empty.notify_one();
    }

    std::shared_ptr<T> wait_and_pop(){
        std::unique_lock<std::mutex>lock(mtx);
        condition_empty.wait(lock,[this](){
            return !data.empty();
        });
        std::shared_ptr<T>const res = std::make_shared<T>(std::move(data.top()));
        data.pop();
        return res;
    }
    void wait_and_pop(T& value){
        std::unique_lock<std::mutex>lock(mtx);
        condition_empty.wait(lock,[this](){
            return !data.empty();
        });
        value = std::move(data.top());
        data.pop();
    }
    std::shared_ptr<T>pop(){
        std::lock_guard<std::mutex>lock(mtx);
        if(data.empty()) {return nullptr;}
        std::shared_ptr<T> s_ptr= std::make_shared<T>(data.top());
        data.pop();
        return s_ptr;
    }
    void pop(T& val){
        std::lock_guard<std::mutex>lock(mtx);
        if(data.empty())   throw empty_stack();
        val = data.top();
        data.pop();
    }
    bool empty() const
    {
        std::lock_guard<std::mutex> lock(mtx);
        return data.empty();
    }
};
```

存在问题，如果在push的时候出现错误(如内存满了)，此时由于我们只是调用了一个线程(notify_one),此时就会导致问题。
解决:
1.在写一个条件变量，来判断当前是否栈满(手动给仓库大小设置一个大小限制)
2.使用notify_all，但是这样会带来线程之间的竞争

### 无锁安全栈

我们使用链表 + 无锁结构实现安全栈
思路:链表依旧由一个虚节点 head构成
当新数据插入的时候，新数据的next指向现在的head节点
将head节点更新为新插入的数据值 同时如果需要弹出的时候，move掉head指向节点 head->next = next

对于push
```c++
    void push(const T & value){
        auto new_node = new StackNode(value);
        do{
            new_node->next = head.load(std::memory_order_acquire);
        }
        //compare_exchange_weak 当比较失败的时候不会让exchange的值赋值给compare的值 并且开销也小
        while(!head.compare_exchange_weak(new_node->next,new_node));
    }
```
对于pop
```c++
    std::shared_ptr<T>pop(){
        ++threads_in_pop;
        StackNode* old_node = nullptr;
        do{
            old_node = head.load();
            if(old_node == nullptr){
                --threads_in_pop;
                return nullptr;
            }
        }while (!head.compare_exchange_weak(old_node,old_node->next));
        std::shared_ptr<T> res;
        if(old_node!= nullptr){
            res.swap(old_node->data);
        }
        try_reclaim(old_node);
        return res;
    }
```
这里不能直接delete old_node 是因为如果是多个线程共同访问到同一个old_node，一个线程执行了delete，另一个线程执行old_node相关就会报错
所以这里会额外使用一个原子变量用来记录正在pop的任务数，一个原子变量用来存储等待删除的任务

当进入到try_reclaim后 首先会进行一个判断是否只有一个线程正在执行pop任务
之后可以额外判断原子变量获取准确状态，判断pop是否仅仅正被当前线程唯一调用
如果只被一个变量调用，就直接删除待删除列表，如果有多个线程且待删除列表不为空，将待删除列表更新给to_be_deleted
```c++
    void try_reclaim(StackNode* node){
        if(threads_in_pop == 1){
            StackNode* nodes_to_delete = to_be_deleted.exchange(nullptr);
            //这里直接减一  如果只有一个线程调用，满足删除状态，就直接删除
            if(!--threads_in_pop){
                delete_nodes(nodes_to_delete);
            }
            else if(nodes_to_delete){
                chain_pending_nodes(nodes_to_delete);
            }
            delete node;
        }
        else{
            chain_pending_node(node);
            --threads_in_pop;
        }
    }
```
try_reclaim函数就是删除old_head或者将其放入待删列表，以及判断是否删除待删列表。

在详细谈一下chain_pending_node函数和to_be_deleted原子变量，to_be_delete实际上存储的是需要删除的结点，由于可能个存在多个pop的线程，为了安全起见这里就用to_be_deleted来作为删除链表的头结点，当且仅当pop线程数为1的时候会释放


```c++
    void chain_pending_node(StackNode* n)
    {
        chain_pending_nodes(n, n);
    }

    void chain_pending_nodes(StackNode* first, StackNode* last)
    {
        //1 先将last的next节点更新为待删列表的首节点
        last->next = to_be_deleted;
        //2  借循环保证 last->next指向正确
        // 将待删列表的首节点更新为first节点
        while (!to_be_deleted.compare_exchange_weak(
                last->next, first));
    }

    void chain_pending_nodes(StackNode* nodes)
    {
        StackNode* last = nodes;
        //1 沿着next指针前进到链表末端
        while (StackNode* const next = last->next)
        {
            last = next;
        }
        //2 将链表放入待删链表中
        chain_pending_nodes(nodes, last);
    }
```
当有多个线程在pop的时候，只能将node放入删除队列中去，放入的时候先会进入    void chain_pending_node(StackNode* nodes)中，调用void chain_pending_nodes(StackNode* first, StackNode* last) 将新增节点node->next = to_be_deleted 然后让to_be_deleted = node(类似push的操作)

而如果不能删除 就重新将删除队列赋值回去 也就是执行  chain_pending_nodes(nodes_to_delete);
让last->next = to_be_deleted（由于之exchange 这里to_be_deleted是nullptr 必须移动到链表尾部），然后让to_be_deleted = first 表示将**原本取出的删除队列放回**


**完整代码参考author_threadsafe_stack.h的SafeThreadStackWithoutMutex**



### 安全队列  -- 这里使用智能指针降低开销
```c++
//使用list来替换
template<typename T>
class threadsafe_queue_ht{
private:
    struct node
    {
        std::shared_ptr<T>data;
        std::unique_ptr<node>next;
    };
    std::mutex head_mutex;
    std::unique_ptr<node>head;
    std::mutex tail_mutex;
    node* tail;
    std::condition_variable data_cond;

    node* get_tail(){
        std::lock_guard<std::mutex>tail_lock(tail_mutex);
        return tail;
    }
    std::unique_ptr<node>pop_head(){
        std::unique_ptr<node>old_head = std::move(head);
        head = std::move(old_head->next);
        return old_head;
    }
    std::unique_lock<std::mutex> wait_for_data(){
        std::unique_lock<std::mutex> head_lock(head_mutex);
        //不为空
        data_cond.wait(head_lock,[&] {return head.get() != get_tail(); }); 
        return std::move(head_lock);   
    }
    std::unique_ptr<node> wait_pop_head()
    {
        std::unique_lock<std::mutex> head_lock(wait_for_data());   
        return pop_head();
    }
    std::unique_ptr<node> wait_pop_head(T& value)
    {
        std::unique_lock<std::mutex> head_lock(wait_for_data());  
        value = std::move(*head->data);
        return pop_head();
    }
    std::unique_ptr<node> try_pop_head()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        if (head.get() == get_tail())
        {
            return std::unique_ptr<node>();
        }
        return pop_head();
    }
    std::unique_ptr<node> try_pop_head(T& value)
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        if (head.get() == get_tail())
        {
            return std::unique_ptr<node>();
        }
        value = std::move(*head->data);
        return pop_head();
    }
public:
    //在构造的时候就声明一个空节点
    threadsafe_queue_ht() : head(new node),tail(head.get()){};
    threadsafe_queue_ht(const threadsafe_queue_ht& other) = delete;
    threadsafe_queue_ht& operator=(const threadsafe_queue_ht& other) = delete;
    threadsafe_queue_ht& operator=(const threadsafe_queue_ht& other) volatile = delete;

    std::shared_ptr<T>wait_and_pop(){
        std::unique_ptr<node>const old_head = wait_pop_head();
        return old_head->data;
    }
    void wait_and_pop(T& value){
        std::unique_ptr<node>const old_head = wait_pop_head(value);
    }

    std::shared_ptr<T> try_pop()
    {
        std::unique_ptr<node> old_head = try_pop_head();
        return old_head ? old_head->data : std::shared_ptr<T>();
    }
    bool try_pop(T& value)
    {
        std::unique_ptr<node> const old_head = try_pop_head(value);
        return old_head == nullptr;
    }
    void push(T new_value)  
    {
        std::shared_ptr<T> new_data(
        std::make_shared<T>(std::move(new_value)));
        std::unique_ptr<node> p(new node);
        node* const new_tail = p.get();

        std::lock_guard<std::mutex> tail_lock(tail_mutex);
        tail->data = new_data;
        tail->next = std::move(p);
        tail = new_tail;
        data_cond.notify_one();
    }
    bool empty()
    {
        std::lock_guard<std::mutex> head_lock(head_mutex);
        return (head.get() == get_tail());
    }
};
```
## 13 实现线程安全的查找表

实现一个类似线程安全的map结构，但是map基于红黑树实现，假设我们要增加或者删除节点，设计思路是依次要删除或增加节点的父节点，然后修改子节点数据。

散列表:
散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在存储器存储位置的数据结构。 也就是说，它通过计算出一个键值的函数，将所需查询的数据映射到表中一个位置来让人访问，这加快了查找速度。 这个映射函数称做散列函数，存放记录的数组称做散列表。

自己设计哈希函数的是应该遵循的规则:
1.得到的散列值是一个非负整数
2.两个相同的键，通过散列函数计算出的散列值也相同
3.两个不同的键，计算出的散列值不同 

如果出现问题三，就会出现哈希冲突，解决方式是将其使用链表法或者开放寻址法
当我们根据key值的后两位计算编号，将编号相同的放入一个链表
<img src="https://cdn.llfc.club/1700962817978.jpg">


1.将链表封装为一个bucket_type支持数据的增删改查
2.将整体的查找表封装为threadsafe_lookup_table实现散列表规则和调度bucket_type
3.在计算哈希的时候，实际上不用加锁

代码实现:
```c++
//13.cpp
template<typename Key,typename Value,typename Hash = std::hash<Key>>
class threadsafe_lookup_table{
private:
    class bucket_type{
        friend  class threadsafe_lookup_table;
    private:
        //存储元素的类型为pair，由key和value构成
        typedef std::pair<Key,Value>bucket_value;
        //构建链表存储元素
        typedef std::list<bucket_value>bucket_data;
        //链表的迭代器
        typedef typename bucket_data::iterator bucket_iterator;
        //链表数据
        bucket_data data;

        //这里使用共享锁
        mutable std::shared_mutex s_mtx;
        //在链表中查找对应元素
        bucket_iterator find_entry_for(const Key & key){
            return std::find_if(data.begin(),data.end(),[&]
                    (bucket_value const& item){
                return item.first == key;
            });
        }
    public:
        //查找key值 返回对应的value 如果没找到 就返回默认值
        //这里可以学习一下这个思路 当需要更新值的时候添加一个 默认值作为是否查找到的判断
        Value value_for(Key const& key,Value const& default_value){
            std::shared_lock<std::shared_mutex>lock(s_mtx);
            bucket_iterator const found_iterator = find_entry_for(key);
            return (found_iterator == data.end()) ? default_value : found_iterator->second;
        }
        //添加/更新key和value
        void add_or_update_mapping(Key const& key, Value const& value){
            std::unique_lock<std::shared_mutex>lock(s_mtx);
            const bucket_iterator found_iterator = find_entry_for(key);
            if(found_iterator == data.end()){
                data.emplace_back(key,value);
            }
            else{
                found_iterator->second = value;
            }
        };
        //删除key和value
        void remove_mapping(Key const& key) {
            std::unique_lock<std::shared_mutex> lock(s_mtx);
            bucket_iterator const found_iterator = find_entry_for(key);
            if (found_iterator != data.end()) {
                data.erase(found_iterator);
            }
        }
    };
    std::vector<std::unique_ptr<bucket_type>>buckets;
    Hash hasher;
    //计算哈希值 并和容器size取模 放置到对应的位置上
    bucket_type& get_bucket(Key const& key)const{
        std::size_t const bucket_index = hasher(key) % buckets.size();
        return *buckets[bucket_index];
    }

public:
    threadsafe_lookup_table(unsigned num_buckets = 20,Hash const& hasher_ = Hash()):
        buckets(num_buckets),hasher(hasher_) {
        for(unsigned i = 0; i < num_buckets;++i){
            buckets[i].reset(new bucket_type);
        }
    }
    threadsafe_lookup_table(threadsafe_lookup_table const& other) = delete ;
    threadsafe_lookup_table&operator=(const threadsafe_lookup_table&) = delete;

    Value value_for(Key const& key,Value const& default_value = Value()){
        return get_bucket(key).value_for(key,default_value);
    }

    void add_or_update_mapping(Key const& key,Value const& value){
        get_bucket(key).add_or_update_mapping(key,value);
    }
    void remove_mapping(Key const& key){
        get_bucket(key).remove_mapping(key);
    }

    std::map<Key,Value>get_map(){
        std::vector<std::unique_lock<std::shared_mutex>> locks;
        for(unsigned int i = 0; i < buckets.size();++i){
            locks.push_back(
                    std::unique_lock<std::shared_mutex>(buckets[i]->s_mtx));
        }
        std::map<Key,Value>res;
        for(unsigned int i = 0;i< buckets.size();++i){
            typename bucket_type::bucket_iterator it = buckets[i]->data.begin();
            for(;it!=buckets[i]->data.end();++it){
                res.insert(*it);
            }
        }
        return res;
    }
};
```
## ***14 线程安全的链表

如果做一个支持多线程并发访问的链表，我们首先想到的是用一个互斥量控制整个链表，达到多线程访问时串行的效果。但是这么做精度不够，需要分化互斥量的功能。我们想到的一个办法就是每个节点都维护一个互斥量，这样能保证多个线程操作不同节点时加不同的锁，减少耦合性。

<img src="https://cdn.llfc.club/1701559209928.jpg">

给出源码实现:

思路 我们创建了一个源节点head 这个结点并不会放置数据
头插时 会把数据放入head后面去
此外程序还需要接受尾插，我们还会写一个尾部节点

每一个节点我们提供一个锁 用来限制访问时候的唯一性

<font color=red>
在这份代码中，你可以学到:
1.常量指针和指针常量:
node* const next：
这种声明方式表示 next 是一个常量指针，指向的对象是可变的。也就是说，你可以通过 next 指针修改指向的对象，但不能修改 next 指针本身指向的位置（即不能让 next 指向其他位置）。
const node* next：
这种声明方式表示 next 是一个指向常量的指针，指向的对象是不可变的。也就是说，你可以修改 next 指针本身指向的位置，但不能通过 next 指针修改指向的对象。

2.使用lamda表达式作为泛型编程参数传入
3.使用**锁传递**的方式，每次遍历的时候上锁
</font> 


```c++
//定义一个源节点
template<typename T>
class threadsafe_list{
private:
    struct node{
        std::mutex mtx;
        std::shared_ptr<T> data;
        std::unique_ptr<node> next;
        //next() unique_ptr默认构造
        node() : next(){}
        node(T const& val):
                data(std::make_shared<T>(val)){};
    };

    node head;
    node* last_node;
    std::mutex last_mtx;
    //尾部指针 用来实现尾插

public:
    threadsafe_list(){
        last_node = &head;
    };
    ~threadsafe_list(){
        remove_if([](const T& value) {return true; });
    }
    threadsafe_list(const threadsafe_list& other) = delete;
    threadsafe_list&operator=(const threadsafe_list) = delete;

    //头插 向头结点(虚节点)后插入一个元素
    void push_front(T const &val){
        std::unique_ptr<node> new_node(new node(val));
        std::lock_guard<std::mutex>lck(head.mtx);
        new_node->next = std::move(head.next);
        head.next = std::move(new_node);

        if(head.next->next == nullptr){
            std::lock_guard<std::mutex>lck(last_mtx);
            last_node  = head.next.get();
        }
    }
    //尾插 向尾部节点后插入一个元素
    void push_back(const T& val){
        //防止和头插同时进行
        std::unique_ptr<node>next_node(new node(val));
        std::lock(last_node->mtx,last_mtx);
        std::lock_guard<std::mutex>last_nck(last_node->mtx,std::adopt_lock);
        std::lock_guard<std::mutex>last_ck(last_mtx,std::adopt_lock);
        last_node->next = std::move(next_node);
        last_node = last_node->next.get();

    }
    template <typename Function>
    void for_each(Function f){
        node* current = &head;
        std::unique_lock<std::mutex>lck(head.mtx);
        //node* const next 常量指针 指向对象可变 但是指向对象的地址不能改变
        while(node* const next = current->next.get()){
            std::unique_lock<std::mutex>next_lk(next->mtx);
            lck.unlock();
            f(*next->data);
            current = next;
            lck = std::move(next_lk);
        }
    }
    //查询
    template <typename Prediect>
    std::shared_ptr<T>find_first_if(Prediect p){
        node* current = &head;
        std::unique_lock<std::mutex>lck(head.mtx);
        while(node* const next = current->next.get()){
            std::unique_lock<std::mutex>next_lck(next->mtx);
            next_lck.lock();
            if(p(*next->data)){
                return next->data;
            }
            current = next;
            next_lck.unlock();
        }
        return std::shared_ptr<T>();
    }
    //删除
    template <typename Prediect>
    void remove_if(Prediect p){
        node* current = &head;
        std::unique_lock<std::mutex>lck(head.mtx);
        while(node* const next = current->next.get()){
            std::unique_lock<std::mutex>next_lck(next->mtx);
            if(p(*next->data)){
                std::unique_ptr<node>old_next = std::move(current->next);
                current->next = std::move(next->next);
                if(current->next == nullptr){
                    std::unique_lock<std::mutex>last_lck(last_mtx);
                    last_node = current;
                }
                next_lck.unlock();
            }
            current = next;
            lck.unlock();
            lck = std::move(next_lck);
        }
    }
    //删除 包含返回值的删除
    template <typename Prediect>
    bool remove_first(Prediect p){
        node* current = &head;
        std::unique_lock<std::mutex>lck(head.mtx);
        while(node* const next = current->next.get()){
            std::unique_lock<std::mutex>next_lck(next->mtx);
            if(p(*next->data)){
                std::unique_ptr<node>old_next = std::move(current->next);
                current->next = std::move(next->next);
                if(current->next == nullptr){
                    std::unique_lock<std::mutex>last_lck(last_mtx);
                    last_node = current;
                }
                next_lck.unlock();
                return true;
            }
            current = next;
            lck.unlock();
            lck = std::move(next_lck);
        }
        return false;
    }
    //插入
    template<typename Prediect>
    void insert_if(Prediect f,const T& value){
        node* current = &head;
        std::unique_lock<std::mutex>lck(head.mtx);
        while(node* next = current->next.get()){
            std::unique_lock<std::mutex>next_lck(next->mtx);
            if(f(*next->data)){
                std::unique_ptr<node>add_node(new node(value));
                auto old_next = std::move(current->next);
                add_node->next = std::move(old_next);
                current->next = std::move(add_node);
                return;
            }
            current = next;
            lck.unlock();
            lck = std::move(next_lck);
        }
    }
};
```


## 15.任务划分和并行计算

### 递归划分
例如在执行快排的时候，在快排的设计中，每层设计调用的排序的递归访问的数据集合互不相关，正好可以使用递归的方式划分
然而事实表明，随着数据集的增大，会导致线程的快速膨胀，所以使用递归的方法一定要限制线程数量增长

一种方式是使用std::hardware_concurrency()设定线程数目


具体参考15.cpp sorter
这个里我们限制了执行任务的线程的数量
同时我们为了防止线程忙等，还会在让主线程等待的时候执行try_sort_chunk
```c++
std::list<T> do_sort(std::list<T>&data){
        if(data.empty()){
            return data;
        }
        std::list<T>result;
        //将data中第一个值移动到result中
        result.splice(result.begin(),data,data.begin());
        T const & partition_val = *result.begin();
        //std::partition 将满足条件的节点放到不满足val的结点之前
        typename std::list<T>::iterator divide_point =
                    std::partition(data.begin(),data.end(),[&](T const& val){
                        return val < partition_val;
                    });
        chunk_to_sort new_lower_chunk;
        new_lower_chunk.data.splice(new_lower_chunk.data.end(),data,data.begin(),divide_point);
        std::future<std::list<T>>new_lower = new_lower_chunk.promise.get_future();
        chunks.push(std::move(new_lower_chunk));
        //限制了任务执行的线程的数量
        if(threads.size() < max_thread_count){
            threads.emplace_back(std::thread(&sorter<T>::sort_thread,this));
        }
        std::list<T>new_higher(do_sort(data));
        result.splice(result.end(),new_higher);
        while(new_lower.wait_for(std::chrono::seconds(0))!= std::future_status::ready){
            //如果本线程排好了自己的半区，会去辅助栈内其他任务来处理数据，避免了盲等的问题
            try_sort_chunk();
        }
        result.splice(result.begin(),new_lower.get());
        return result;
    }
```

### 按工作类别划分
假定有这么一个场景 A B C分别在不同的线程中处理不同的任务，任务却要以流水线A-B-C的方式执行
可以这样抽象出一个Actor类，它包含消息的投递，消息的处理，以及消息队列的管理，并且它是一个单例类，全局唯一。

单例实现
```c++
template <typename ClassType,typename QueType>
class ActorSingle{
public:
    static ClassType& instance(){
        static ClassType as;
        return as;
    }
    ~ActorSingle(){

    }
    void PostMsg(const QueType& data){
        _que.push(data);
    }
private:
    ActorSingle():_bstop(false){
    }
    ActorSingle(const ActorSingle&) = delete;
    ActorSingle(ActorSingle&&) = delete;
    ActorSingle& operator = (const ActorSingle&) = delete;

    std::atomic<bool> _bstop;
    threadsafe_queue_ht<QueType>  _que;
    std::thread _thread;
};
```

_que用来存储要处理的信息,这是一个线程安全的队列。_thread是要处理任务的线程。
_bstop表示线程停止的标记


我们给ThreadSafeQue添加一个原子变量_bstop表示线程停止的标记
并且添加停止通知函数NotifyStop
这样就可以通过Actor控制que是否关闭

简单提一下ClassA B C的实现 A->B->C

```c++
struct MsgClassA {
    std::string name;
    friend std::ostream& operator << (std::ostream& os, const MsgClassA& ca) {
        os << ca.name;
        return os;
    }
};
class ClassA : public ActorSingle<ClassA, MsgClassA> {
    friend class ActorSingle<ClassA, MsgClassA>;
public:
    ~ClassA() {
        _bstop = true;
        _que.notify_stop();
        _thread.join();
        std::cout << "ClassA destruct " << std::endl;
    }
    void DealMsg(std::shared_ptr<MsgClassA> data) {
        std::cout << "class A deal msg is " << *data << std::endl;
        MsgClassB msga;
        msga.name = "llfc_B";
        ClassB::instance().PostMsg(msga);
    }
private:
    ClassA(){
        _thread = std::thread([this]() {
            for (; (_bstop.load() == false);) {
                std::cout << "thread A " << std::this_thread::get_id() << std::endl;
                std::shared_ptr<MsgClassA> data = _que.wait_and_pop();
                if (data == nullptr) {
                    continue;
                }
                DealMsg(data);
            }
            std::cout << "ClassA thread exit " << std::endl;
        });
    }
};
```

classA使用继承的方式，ClassB、ClassC也一样采用继承的方式
A的线程将自己的data取出后，执行(输出class A deal...)，之后声明B 并执行B的线程，直到classC

classC的deal只处理自己。
通过继承实现了A->B->C

直到主函数结束 一次析构classA B C 
因为是栈的形式 所以析构是依次析构C B A
```c++
thread A 140273589921536
class A deal msg is llfc_A
thread A 140273589921536
thread B 140273606706944
class B deal msg is llfc_B
thread C 140273598314240
class C deal msg is llfc_C
main process exited!
ClassC thread exit 
ClassC destruct 
ClassB thread exit 

```


## ***16.并行计算
### 并行版本for_each

首先简单介绍一下for_each

for_each的原型函数
```c++
template<class InputIterator, class Function>
  Function for_each(InputIterator first, InputIterator last, Function fn)
{
  while (first!=last) {
    fn (*first);
    ++first;
  }
  return fn;      // or, since C++11: return move(fn);
}
```

```c++
template<typename T>
class AddVal{
private:
    T _val;
public :
    AddVal(const T& val):_val(val){}
    void operator()(T& val){
        val += _val;
    }
};
void test_for_each(){
    std::vector<int>coll = {0,1,2,3,4,5,6,7};
    std::for_each(coll.begin(),coll.end(),AddVal<int>(50));
    auto print = [](int i){ std::cout << i << " "; };
    std::for_each(coll.begin(),coll.end(),print);
}

//output
//50 51 52 53 54 55 56 57
```
我们给出并发计算的具体实现代码
```c++
template<typename Iterator,typename Func>
void parallel_for_each(Iterator first,Iterator last,Func f){
    unsigned long const length = std::distance(first,last);
    if(!length){return;}
    //处理的数量不超过25个则用单线程。否则根据处理的数量划分任务
    unsigned long const min_per_thread = 25;
    //计算一个长度为 length 的任务或数据块分配到多少个线程中比较合适
    unsigned long const max_per_thread = (length + min_per_thread -1 )/min_per_thread;
    unsigned long const hardware_thread = std::thread::hardware_concurrency();
    unsigned long const num_threads = std::min(hardware_thread!=0 ? hardware_thread : 2 ,max_per_thread);
    unsigned long const block_size = length / num_threads;
    std::vector<std::future<void>>futures(num_threads - 1);
    std::vector<std::thread> threads(num_threads - 1);
    join_threads joiner(threads);
    Iterator block_start = first;

    for (unsigned long i = 0; i < (num_threads - 1) ;++i){
        Iterator block_end = block_start;
        std::advance(block_end,block_size);
        std::packaged_task<void(void)>task([=](){
            std::for_each(block_start,block_end,f);
        });
        futures[i] = task.get_future();
        threads[i] = std::thread(std::move(task));
        block_start = block_end;
    }
    //使用num_threads-1个线程并行处理for_each，剩下的主线程处理余下的for_each，最后通过futures.get汇总
    std::for_each(block_start, last, f);
    for(unsigned long i = 0; i <(num_threads - 1); i++){
        futures[i].get();
    }
}
```

#### find的并行计算

find 的并行查找方式还是分两种，一种是将要查找的区间划分为几个段，每段交给一个线程查找。
另一种是采用递归的方式每次折半，前半部分交给一个线程查找，后半部分留在本线程查找。


这里只说第一种:

```c++
template <typename Iterator, typename MatchType>
Iterator parallel_find(Iterator first, Iterator last,MatchType match){
    struct find_element{
        void operator()(Iterator begin,Iterator end,MatchType match,
                        std::promise<Iterator>*result,
                        std::atomic<bool>*done_flag)
        {
                try {
                    for(;(begin!=end)&&!done_flag->load();++begin){
                        if(*begin==match){
                            result->set_value(begin);
                            done_flag->store(true);
                            return;
                        }
                    }
                }
                catch (const std::exception&){
                    try {
                        result->set_exception(std::current_exception());
                        done_flag->store(true);
                    }
                    catch(...){}
                }
        }
    };
    unsigned long const length = std::distance(first, last);
    if (!length)
        return last;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread;
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
    unsigned long const block_size = length / num_threads;

    std::promise<Iterator>result;
    std::atomic<bool>done_flag(false);
    std::vector<std::thread>threads(num_threads - 1);
    {
        join_threads joiner(threads);
        Iterator block_start = first;
        for (unsigned long i = 0; i < num_threads - 1 ;++i){
            Iterator block_end = block_start;
            std::advance(block_end, block_size);
            threads[i] = std::thread(find_element(),block_start,block_end,match,&result,&done_flag);
            block_start = block_end;
        }
        find_element()(block_start, last, match, &result, &done_flag);
    }
    //没有找到就返回last
    if(!done_flag.load()){return last;}
    return result.get_future().get();
}
```
将数据分配给不同的线程进行查找

#### *** 求和并发计算 std::partial_sum
我们将一个数组可以分为A\B\C三个部分，这里需要考虑的是线程B需要用到A的部分，也就是说这里存在一个并发任务的同步问题
每个线程优先处理分区的最后一个元素，通过promise设置给其他线程，在这个阶段线程之间是串行的，等到所有线程都开始计算其他位置后就是并行了。

```c++
// 实现并发的 std::partial_sum
template<typename Iterator>
void parallel_partial_sum(Iterator first,Iterator last){
    //获取传入数据的类型
    typedef typename Iterator::value_type value_type;
    struct process_chunk{
        void operator()(Iterator begin,Iterator last,
            std::future<value_type>* previous_end_value,
            std::promise<value_type>* end_value)
        {
            try{
                Iterator end = last;
                ++end;
                 /* std::partial_sum 是 C++ 标准库中的一个算法
                 *  用于计算一个序列的部分和,将结果存放在第三个参数定义的位置
                 *  如果想要计算到a[i]出 partial_sum的第二个参数必须输入到i+1 所以定义++end
                 *  2 0 2 4 2 2
                 *  2 2 4 8 10 12
                 *  此时last位置就是begin 到 last的部分和
                 */
                std::partial_sum(begin,end,begin);
                // 如果previous_end_value 不是0 也就是这不是第一个区间
                // 那么会将前一个块的结束值加到当前块的最后一个元素上
                // 这是为了保证每个块的部分和是连续的。
                if(previous_end_value){
                    value_type addend = previous_end_value->get();
                    // 此处相当于 前面数据和 + 当前区间数据和
                    *last += addend;
                    if(end_value){
                        //将结果写入到end_value中
                        end_value->set_value(*last);
                    }
                    // 将前一个块的结束值加到当前块中的每个元素上 保证当前位置的数据结果是含有前面部分和的
                    std::for_each(begin,end,[addend](value_type& item){
                        item += addend;
                    });
                }
                //如果是第一个值，就将end_value设置为last的值
                else if(end_value){
                    end_value->set_value(*last);
                }
            }
            catch(...){
                if(end_value){
                    end_value->set_exception(std::current_exception());
                }
                else{
                    throw;
                }
            }
        }
    };

    unsigned int const length = std::distance(first,last);
    if (!length) {
        return;
    }
    unsigned long const min_per_thread = 25;     //⇽-- - 12
    unsigned long const max_threads = (length + min_per_thread - 1) / min_per_thread;
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
    unsigned long const block_size = length / num_threads;
    typedef typename Iterator::value_type value_type;

    std::vector<std::thread>threads(num_threads -1 );
    std::vector<std::promise<value_type>>end_values(num_threads -1);
    std::vector<std::future<value_type>>previous_end_values(num_threads -1);

    join_threads joiner(threads);
    Iterator block_start = first;
    for(unsigned int i = 0; i < num_threads -1 ;++i){
        Iterator block_last = block_start;
        std::advance(block_last,block_size);
        threads[i] = std::thread(process_chunk(),block_start,block_last,
                                 (i!=0) ? &previous_end_values[i-1]: 0,
                                 &end_values[i]);
        block_start = block_last;
        // block_last是已经被加过的了 所以此处block_start就应该向前进一位
        ++block_start;
        previous_end_values.emplace_back(end_values[i].get_future());
    }
    Iterator final_element = block_start;
    std::advance(final_element, std::distance(block_start, last) - 1);
    process_chunk()(block_start, final_element,
            (num_threads > 1) ? &previous_end_values.back() : 0,
                    0);
}
```

## 17.中断线程

一个可中断线程的大体实现是这样的
```c++
//17.cpp
class interruptible_thread
{
    std::thread internal_thread;
    interrupt_flag* flag;
public:
    template<typename FunctionType>
    interruptible_thread(FunctionType f)
    {
        std::promise<interrupt_flag*> p;  
        internal_thread = std::thread([f, &p] {    
            p.set_value(&this_thread_interrupt_flag);
            f();    
        });
        flag = p.get_future().get();    
    }
    void join() {
        internal_thread.join();
    }
    void interrupt()
    {
        if (flag)
        {
            flag->set();    
        }
    }
};
```
interrupt_flag 中断标记 其set操作用来标记中断
internal_thread为内部线程，其回调函数内部先设置interrupt_flag*类型的promise值，再执行回调函数

在interruptible_thread构造函数中等待internal_thread回调函数内部设置好flag的promise值后再退出
this_thread_interrupt_flag是我们定义的线程变量thread_local interrupt_flag this_thread_interrupt_flag

中断标记interrupt_flag类，主要是用来设置中断标记和判断是否已经中断，有可能挂起在条件变量的wait操作上，此时中断就需要唤醒挂起的线程。


使用condition_variable_any支持任意类型的条件变量

**std::condition_variable_any 是 C++ 标准库中提供的一个条件变量类，它可以与任何满足条件的锁结合使用。与 std::condition_variable 不同的是，std::condition_variable_any 可以使用任何满足条件的锁类型，而不仅仅是 std::mutex**

```c++
class interrupt_flag
{
    std::atomic<bool> flag;
    std::condition_variable* thread_cond;
    std::condition_variable_any* thread_cond_any;
    std::mutex set_clear_mutex;
public:
    interrupt_flag() :
        thread_cond(0), thread_cond_any(0)
    {}
    void set()
    {
        flag.store(true, std::memory_order_relaxed);
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        if (thread_cond)
        {
            thread_cond->notify_all();
        }
        else if (thread_cond_any) {
            thread_cond_any->notify_all();
        }
    }
    bool is_set() const
    {
        return flag.load(std::memory_order_relaxed);
    }
    void set_condition_variable(std::condition_variable& cv)
    {
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        thread_cond = &cv;
    }
    void clear_condition_variable()
    {
        std::lock_guard<std::mutex> lk(set_clear_mutex);
        thread_cond = 0;
    }
    template<typename Lockable>
    void wait(std::condition_variable_any& cv, Lockable& lk) {
        struct custom_lock {
            interrupt_flag* self;
            Lockable& lk;
            custom_lock(interrupt_flag* self_, std::condition_variable_any& cond, Lockable& lk_) :
                self(self_), lk(lk_) {
                self->set_clear_mutex.lock();
                self->thread_cond_any = &cond;
            }
            void unlock() {
                lk.unlock();
                self->set_clear_mutex.unlock();
            }
            void lock() {
                std::lock(self->set_clear_mutex, lk);
            }
            ~custom_lock() {
                self->thread_cond_any = 0;
                self->set_clear_mutex.unlock();
            }
        };
        custom_lock cl(this, cv, lk);
        interruption_point();
        cv.wait(cl);
        interruption_point();
    }
};
```


## 18.常见异常
### 1.引用变量的释放异常
也就是常说的在局部变量中调用引用，当局部变量被释放后，引用就自然而然的无效了，此时再访问就会出现错误
例如:
```c++
void reference_invalid()
{
     class task_data {
     public:
         task_data(int i):_data(new int(i)){}
         ~task_data() { delete _data; }
         int* _data;
     };
     std::queue<std::function<void()>> task_que;
     for (int i = 0; i < 10; i++) {
         task_data data(i);
         task_que.push([&data]() {
             (*data._data)++;
             std::cout << "data is " << *data._data << std::endl;
             });
     }
    auto res_future =  std::async([&task_que]() {
            for (;;) {
                if (task_que.empty()) {
                    break;
                }
                auto& task = task_que.front();
                task();
                task_que.pop();
            }
        });
    res_future.wait();
}
```
此时lamda表达式捕获引用对象，但是在循环结束的时候引用就自然失效了，进而导致输出的data都是空的

一种改进的思路 采用智能指针shared_ptr
```c++
//17.cpp
void reference_sharedptr()
 {
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() { delete _data; }
         int* _data;
     };
     std::queue<std::function<void()>> task_que;
     for (int i = 0; i < 10; i++) {
         std::shared_ptr<task_data> taskptr = std::make_shared<task_data>(i);
         task_que.push([taskptr]() {
            (*( taskptr->_data))++;
             std::cout << "data is " << *(taskptr->_data) << std::endl;
             });
     }
     auto res_future = std::async([&task_que]() {
         for (;;) {
             if (task_que.empty()) {
                 break;
             }
             auto& task = task_que.front();
             task();
             task_que.pop();
         }
         });
     res_future.wait();
 }
```
注意此处做了两处修改:
1.将先前的引用更换为task_data的智能指针
2.在lamda表达式中把引用捕获换位拷贝捕获 -- 这非常重要，如果还是引用捕获将任然报错

解释 这里主要涉及到了shared_ptr指针计数的特性
1.当出现赋值的时候，会导致计数次数增加
```c++
std::shared_ptr<int> ptr1 = std::make_shared<int>(42); // 引用计数为1
std::shared_ptr<int> ptr2 = ptr1; // 复制构造，引用计数增加为2
std::shared_ptr<int> ptr3;
ptr3 = ptr1; // 赋值，引用计数增加为3
```

2.使用make_share方法的时候会创建一个新的对象，使用reset重新指向一个新资源的时候，计数次数不会改变，而使用复制构造的时候，计数次数会加一
```c++
std::shared_ptr<int> ptr1 = std::make_shared<int>(42); // 引用计数为1
ptr1.reset(new int(10)); // 重新指向新的资源，引用计数不变
std::shared_ptr<int> ptr2(ptr1); // 复制构造，引用计数增加为2
```

3.当reset置位为空的时候会导致或shared_ptr离开作用域的时候，计数次数会减少
```c++
std::shared_ptr<int> ptr1 = std::make_shared<int>(42); // 引用计数为1
{
    std::shared_ptr<int> ptr2(ptr1); // 复制构造，引用计数增加为2
    ptr2.reset(); // 引用计数减少为1
} // ptr2 被销毁，引用计数减少为0，资源被释放
```

这里lamda表达式使用复制捕获，传入lamda表达式的时候，计数次数会加一，保证在后续调用的时候任然有效


### 2.浅拷贝
```c++
void shallow_copy2(){
     class task_data {
     public:
         task_data(int i) :_data(new int(i)) {}
         ~task_data() {
             std::cout << "call task_data destruct" << std::endl;
             delete _data;
         }
         int* _data;
     };
     auto task_call = []() -> task_data {
         task_data data(100);
         return data;
     };
     task_call();
 }
```
如上面的例子所示，在return的时候，如果没有写深拷贝，调用任然是浅拷贝，当data离开函数作用域，就会被析构，进而导致返回值也被析构了

修改  我们声明深拷贝功能
```c++
void normal_copy() {
    class task_data {
    public:
        task_data(int i) :_data(new int(i)) {}
        ~task_data() {
            std::cout << "call task_data destruct" << std::endl;
            delete _data;
        }
        task_data(const task_data& src) {
            if(this->_data == src._data){return;}
            _data = new int(*(src._data));
        }
        task_data(task_data&& src) {
            if(this->_data == src._data){return;}
            _data = new int(*(src._data));
        }
        task_data& operator=(const task_data& other){
            if(this != &other){
                delete _data;
                _data = new int(*(other._data));
            }
            return *this;
        }
        int* _data;
    };
    auto task_call = []() -> task_data {
        task_data data(100);
        return data;
    };
    task_call();
}
```

### 3.线程管控
例如我们实现了一个单生产单消费的模型：
```c++
 std::atomic<bool>  b_stop = false;
class ProductConsumerMgr {
public:
    ProductConsumerMgr(){
        _consumer = std::thread([this]() {
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _consume_cv.wait(lock, [this]() {
                    if (_data_que.empty()) {
                        return false;
                        }
                    return true;
                    });
                int data = _data_que.front();
                _data_que.pop();
                std::cout << "pop data is " << data << std::endl;
                lock.unlock();
                _producer_cv.notify_one();
                }
            });
        _producer = std::thread([this]() {
            int data = 0;
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _producer_cv.wait(lock, [this]() {
                    if (_data_que.size() > 100) {
                        return false;
                    }
                    return true;
                    });
                _data_que.push(++data);
                std::cout << "push data is " << data << std::endl;
                lock.unlock();
                _consume_cv.notify_one();
            }
            });
    }
    ~ProductConsumerMgr(){
        _producer.join();
        _consumer.join();
    }
private:
    std::mutex _mtx;
    std::condition_variable _consume_cv;
    std::condition_variable _producer_cv;
    std::queue<int> _data_que;
    std::thread _consumer;
    std::thread _producer;
};


//调用
  void TestProducerConsumer()
  {
     //按键声明 按下ctrl+c修改b_stop
      SetConsoleCtrlHandler((PHANDLER_ROUTINE)CtrlHandler, TRUE);
      ProductConsumerMgr mgr;
      while (!b_stop) {
          std::this_thread::sleep_for(std::chrono::milliseconds(10));
      }
    }
```

在上述例子中可以同通过在外部调整b_stop的方式来控制两个线程的关闭，b_stop修改后mgr会立即进入析构，但是如果生产者效率变慢，例如一个小时生产一个数据放入队列，此时修改b_stop后并不会退出程序，因为析构函数会卡住，无法**立即关闭**

修改方案，在析构的时候立即通知两个线程打开阻塞，并在解开阻塞后判断停止逻辑

```c++
    ProductConsumerMgr(){
        _consumer = std::thread([this]() {
            while (!b_stop) {
                std::unique_lock<std::mutex> lock(_mtx);
                _consume_cv.wait(lock, [this]() {
                    if (b_stop) {
                        return true;
                    }
                    if (_data_que.empty()) {
                        return false;
                        }
                    return true;
                    });
                if (b_stop) {
                    return ;
                }
                int data = _data_que.front();
                _data_que.pop();
                std::cout << "pop data is " << data << std::endl;
                lock.unlock();
                _producer_cv.notify_one();
                }
            });
        _producer = std::thread([this]() {
            int data = 0;
            while (!b_stop) {
                std::this_thread::sleep_for(std::chrono::seconds(5));
                std::unique_lock<std::mutex> lock(_mtx);
                _producer_cv.wait(lock, [this]() {
                    if (b_stop) {
                        return true;
                    }
                    if (_data_que.size() > 100) {
                        return false;
                    }
                    return true;
                    });
                if (b_stop) {
                    return ;
                }
                _data_que.push(++data);
                std::cout << "push data is " << data << std::endl;
                lock.unlock();
                _consume_cv.notify_one();
            }
            });
    }
    ~ProductConsumerMgr(){
    _consume_cv.notify_one();
    _producer_cv.notify_one();
    _producer.join();
    _consumer.join();
}
```

此时如果修改b_stop程序将立即关闭，但是会丢失任务队列里的内容

